{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28437139",
   "metadata": {},
   "source": [
    "## Library Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8657dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from pyearth import Earth\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662eeb0",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9eba358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>297281012</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3320000000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>100474819</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>348000000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>109546590</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          x001      x002  x003     x004          x005  x006         x007  \\\n",
       "0   0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31    266117.20   \n",
       "1   1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00  11927742.92   \n",
       "2   2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00    774385.01   \n",
       "3   3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   6324375.16   \n",
       "4   4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21    169860.29   \n",
       "\n",
       "        x008       x009  ...    x757           x758  x759   x760  x761   x762  \\\n",
       "0   934577.0    14539.0  ...  0.0007      297281012  0.13    5.0     5    2.0   \n",
       "1  1798051.0  1051272.0  ...  0.1136  3320000000000  0.08  661.0     0  350.0   \n",
       "2   375738.0   144143.0  ...  0.0029      100474819  0.39   39.0     2   18.0   \n",
       "3  1932094.0    10055.0  ...  0.0000   348000000000  0.25    2.0     1    0.0   \n",
       "4   474253.0    17914.0  ...  0.0005      109546590  0.11   11.0     1    3.0   \n",
       "\n",
       "      x763    x764  x765   y  \n",
       "0   8.5127   14.28 -0.75   5  \n",
       "1   1.5700  160.12   NaN   1  \n",
       "2   9.6800   25.06 -0.49  11  \n",
       "3   4.5316  117.76  1.64   1  \n",
       "4  16.2717    5.81 -0.42   5  \n",
       "\n",
       "[5 rows x 767 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c3e82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 767)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344e2db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>6.507826e+10</td>\n",
       "      <td>7882.15</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>1.712586e+09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>583617.74</td>\n",
       "      <td>862986.0</td>\n",
       "      <td>63872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>90204869909</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.1213</td>\n",
       "      <td>27.95</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>3.122741e+09</td>\n",
       "      <td>4682.13</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.040914e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190000.65</td>\n",
       "      <td>688710.0</td>\n",
       "      <td>35407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>37449565014</td>\n",
       "      <td>0.02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>10.18</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.888719e+10</td>\n",
       "      <td>7495.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>2.160400e+09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>351570.67</td>\n",
       "      <td>841523.0</td>\n",
       "      <td>170240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>10847937619</td>\n",
       "      <td>0.83</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.8513</td>\n",
       "      <td>21.27</td>\n",
       "      <td>19.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>7.727427e+10</td>\n",
       "      <td>4003.76</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>5.519591e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320216.05</td>\n",
       "      <td>466131.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37200096</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0511</td>\n",
       "      <td>18.38</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>4.184868e+09</td>\n",
       "      <td>34874.72</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.046217e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3349978.53</td>\n",
       "      <td>3711028.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16400000000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6512</td>\n",
       "      <td>149.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          x001      x002  x003     x004          x005  x006  \\\n",
       "0  5380  6.507826e+10   7882.15  6.82  0.00210  1.712586e+09  0.39   \n",
       "1  5381  3.122741e+09   4682.13  8.17  0.00010  1.040914e+09  0.00   \n",
       "2  5382  3.888719e+10   7495.57  7.15  0.00285  2.160400e+09  0.42   \n",
       "3  5383  7.727427e+10   4003.76  6.53  0.00165  5.519591e+09  0.00   \n",
       "4  5384  4.184868e+09  34874.72  6.39  0.00065  1.046217e+09  0.50   \n",
       "\n",
       "         x007       x008      x009  ...    x756    x757            x758  x759  \\\n",
       "0   583617.74   862986.0   63872.0  ...  0.0380  0.0010     90204869909  0.26   \n",
       "1   190000.65   688710.0   35407.0  ...  0.1866  0.0192     37449565014  0.02   \n",
       "2   351570.67   841523.0  170240.0  ...  0.0100  0.0017     10847937619  0.83   \n",
       "3   320216.05   466131.0      35.0  ...  0.4636  0.0000        37200096  0.51   \n",
       "4  3349978.53  3711028.0    1757.0  ...  2.8737  0.0001  16400000000000  0.12   \n",
       "\n",
       "   x760  x761  x762     x763    x764   x765  \n",
       "0   8.0     5   5.0  30.1213   27.95  -0.49  \n",
       "1  16.0     1   8.0   2.1282   10.18   0.55  \n",
       "2  35.0     1  19.0   7.8513   21.27  19.09  \n",
       "3   1.0     4   0.0   9.0511   18.38   4.11  \n",
       "4   2.0     1   2.0   2.6512  149.68   0.02  \n",
       "\n",
       "[5 rows x 766 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e61416",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test['id']\n",
    "test.drop(columns = 'id',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c9272",
   "metadata": {},
   "source": [
    "# Testing just catboost lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3d20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['y','id'])\n",
    "y = train['y']\n",
    "cols = X.columns\n",
    "y = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b00a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = pd.DataFrame(sc.transform(X))\n",
    "test = pd.DataFrame(sc.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17775893",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xknn = KNNImputer(n_neighbors=7).fit(X)\n",
    "X = Xknn.transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "#X.columns = cols\n",
    "\n",
    "#X_test = Xknn.transform(X_test)\n",
    "#X_test = pd.DataFrame(X_test)\n",
    "\n",
    "test = Xknn.transform(test)\n",
    "test = pd.DataFrame(test)\n",
    "#test.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ce06521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "988f1420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8835235\ttotal: 162ms\tremaining: 162ms\n",
      "1:\tlearn: 0.8479602\ttotal: 179ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2008c99a0d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = CatBoostRegressor(iterations=2, \n",
    "                     #     depth=2, \n",
    "                     #     learning_rate=1, \n",
    "                     #     loss_function='RMSE')\n",
    "\n",
    "#model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb874aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.372486453314375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.exp(model.predict(X_test))\n",
    "np.sqrt(mean_squared_error(preds, np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456846b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "grid = {'iterations': [120, 150, 180],\n",
    "        'learning_rate': [0.03],\n",
    "        'depth': [8,15,25],\n",
    "        'l2_leaf_reg': [3,5]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "grid = RandomizedSearchCV(CatBoostRegressor(random_state=1),\n",
    "                          param_distributions =grid, \n",
    "                          cv=cv, n_jobs=-1,\n",
    "                          verbose=4, \n",
    "                          scoring = 'neg_root_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1aae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_CBC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e25822af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9895895\ttotal: 126ms\tremaining: 18.7s\n",
      "1:\tlearn: 0.9809784\ttotal: 212ms\tremaining: 15.7s\n",
      "2:\tlearn: 0.9729746\ttotal: 297ms\tremaining: 14.5s\n",
      "3:\tlearn: 0.9647217\ttotal: 386ms\tremaining: 14.1s\n",
      "4:\tlearn: 0.9571329\ttotal: 472ms\tremaining: 13.7s\n",
      "5:\tlearn: 0.9494932\ttotal: 562ms\tremaining: 13.5s\n",
      "6:\tlearn: 0.9417738\ttotal: 655ms\tremaining: 13.4s\n",
      "7:\tlearn: 0.9346472\ttotal: 748ms\tremaining: 13.3s\n",
      "8:\tlearn: 0.9281773\ttotal: 840ms\tremaining: 13.2s\n",
      "9:\tlearn: 0.9212410\ttotal: 940ms\tremaining: 13.2s\n",
      "10:\tlearn: 0.9148369\ttotal: 1.03s\tremaining: 13s\n",
      "11:\tlearn: 0.9090863\ttotal: 1.13s\tremaining: 13s\n",
      "12:\tlearn: 0.9029513\ttotal: 1.22s\tremaining: 12.9s\n",
      "13:\tlearn: 0.8965543\ttotal: 1.31s\tremaining: 12.8s\n",
      "14:\tlearn: 0.8902865\ttotal: 1.4s\tremaining: 12.6s\n",
      "15:\tlearn: 0.8844293\ttotal: 1.49s\tremaining: 12.5s\n",
      "16:\tlearn: 0.8789073\ttotal: 1.58s\tremaining: 12.4s\n",
      "17:\tlearn: 0.8734408\ttotal: 1.67s\tremaining: 12.2s\n",
      "18:\tlearn: 0.8679607\ttotal: 1.76s\tremaining: 12.2s\n",
      "19:\tlearn: 0.8626354\ttotal: 1.85s\tremaining: 12s\n",
      "20:\tlearn: 0.8576244\ttotal: 1.94s\tremaining: 11.9s\n",
      "21:\tlearn: 0.8525441\ttotal: 2.03s\tremaining: 11.8s\n",
      "22:\tlearn: 0.8478123\ttotal: 2.12s\tremaining: 11.7s\n",
      "23:\tlearn: 0.8433308\ttotal: 2.21s\tremaining: 11.6s\n",
      "24:\tlearn: 0.8387089\ttotal: 2.3s\tremaining: 11.5s\n",
      "25:\tlearn: 0.8345782\ttotal: 2.39s\tremaining: 11.4s\n",
      "26:\tlearn: 0.8301130\ttotal: 2.48s\tremaining: 11.3s\n",
      "27:\tlearn: 0.8257815\ttotal: 2.57s\tremaining: 11.2s\n",
      "28:\tlearn: 0.8216300\ttotal: 2.66s\tremaining: 11.1s\n",
      "29:\tlearn: 0.8180491\ttotal: 2.75s\tremaining: 11s\n",
      "30:\tlearn: 0.8146429\ttotal: 2.85s\tremaining: 11s\n",
      "31:\tlearn: 0.8107014\ttotal: 2.94s\tremaining: 10.9s\n",
      "32:\tlearn: 0.8068463\ttotal: 3.03s\tremaining: 10.7s\n",
      "33:\tlearn: 0.8031801\ttotal: 3.13s\tremaining: 10.7s\n",
      "34:\tlearn: 0.7999642\ttotal: 3.23s\tremaining: 10.6s\n",
      "35:\tlearn: 0.7967739\ttotal: 3.33s\tremaining: 10.5s\n",
      "36:\tlearn: 0.7935659\ttotal: 3.42s\tremaining: 10.5s\n",
      "37:\tlearn: 0.7904546\ttotal: 3.52s\tremaining: 10.4s\n",
      "38:\tlearn: 0.7875280\ttotal: 3.62s\tremaining: 10.3s\n",
      "39:\tlearn: 0.7846439\ttotal: 3.73s\tremaining: 10.3s\n",
      "40:\tlearn: 0.7817417\ttotal: 3.83s\tremaining: 10.2s\n",
      "41:\tlearn: 0.7787389\ttotal: 3.93s\tremaining: 10.1s\n",
      "42:\tlearn: 0.7760232\ttotal: 4.03s\tremaining: 10s\n",
      "43:\tlearn: 0.7734110\ttotal: 4.12s\tremaining: 9.92s\n",
      "44:\tlearn: 0.7708639\ttotal: 4.21s\tremaining: 9.82s\n",
      "45:\tlearn: 0.7685736\ttotal: 4.3s\tremaining: 9.72s\n",
      "46:\tlearn: 0.7665802\ttotal: 4.39s\tremaining: 9.62s\n",
      "47:\tlearn: 0.7641437\ttotal: 4.48s\tremaining: 9.51s\n",
      "48:\tlearn: 0.7617985\ttotal: 4.56s\tremaining: 9.41s\n",
      "49:\tlearn: 0.7592649\ttotal: 4.65s\tremaining: 9.3s\n",
      "50:\tlearn: 0.7565706\ttotal: 4.74s\tremaining: 9.21s\n",
      "51:\tlearn: 0.7544638\ttotal: 4.84s\tremaining: 9.11s\n",
      "52:\tlearn: 0.7521896\ttotal: 4.92s\tremaining: 9.01s\n",
      "53:\tlearn: 0.7501902\ttotal: 5.02s\tremaining: 8.92s\n",
      "54:\tlearn: 0.7483665\ttotal: 5.11s\tremaining: 8.82s\n",
      "55:\tlearn: 0.7466272\ttotal: 5.2s\tremaining: 8.72s\n",
      "56:\tlearn: 0.7437513\ttotal: 5.29s\tremaining: 8.63s\n",
      "57:\tlearn: 0.7419999\ttotal: 5.38s\tremaining: 8.54s\n",
      "58:\tlearn: 0.7401406\ttotal: 5.47s\tremaining: 8.44s\n",
      "59:\tlearn: 0.7377741\ttotal: 5.56s\tremaining: 8.34s\n",
      "60:\tlearn: 0.7357186\ttotal: 5.65s\tremaining: 8.25s\n",
      "61:\tlearn: 0.7336975\ttotal: 5.74s\tremaining: 8.15s\n",
      "62:\tlearn: 0.7317820\ttotal: 5.83s\tremaining: 8.06s\n",
      "63:\tlearn: 0.7300821\ttotal: 5.93s\tremaining: 7.96s\n",
      "64:\tlearn: 0.7282902\ttotal: 6.02s\tremaining: 7.87s\n",
      "65:\tlearn: 0.7262370\ttotal: 6.11s\tremaining: 7.78s\n",
      "66:\tlearn: 0.7240110\ttotal: 6.2s\tremaining: 7.68s\n",
      "67:\tlearn: 0.7221031\ttotal: 6.29s\tremaining: 7.58s\n",
      "68:\tlearn: 0.7203832\ttotal: 6.38s\tremaining: 7.49s\n",
      "69:\tlearn: 0.7185545\ttotal: 6.47s\tremaining: 7.39s\n",
      "70:\tlearn: 0.7172157\ttotal: 6.55s\tremaining: 7.29s\n",
      "71:\tlearn: 0.7157622\ttotal: 6.65s\tremaining: 7.21s\n",
      "72:\tlearn: 0.7146296\ttotal: 6.74s\tremaining: 7.11s\n",
      "73:\tlearn: 0.7132523\ttotal: 6.84s\tremaining: 7.03s\n",
      "74:\tlearn: 0.7115036\ttotal: 6.93s\tremaining: 6.93s\n",
      "75:\tlearn: 0.7098500\ttotal: 7.03s\tremaining: 6.84s\n",
      "76:\tlearn: 0.7081091\ttotal: 7.13s\tremaining: 6.76s\n",
      "77:\tlearn: 0.7066126\ttotal: 7.22s\tremaining: 6.67s\n",
      "78:\tlearn: 0.7046211\ttotal: 7.31s\tremaining: 6.57s\n",
      "79:\tlearn: 0.7033122\ttotal: 7.41s\tremaining: 6.48s\n",
      "80:\tlearn: 0.7019078\ttotal: 7.5s\tremaining: 6.39s\n",
      "81:\tlearn: 0.7003430\ttotal: 7.6s\tremaining: 6.3s\n",
      "82:\tlearn: 0.6988419\ttotal: 7.69s\tremaining: 6.21s\n",
      "83:\tlearn: 0.6970957\ttotal: 7.78s\tremaining: 6.12s\n",
      "84:\tlearn: 0.6956515\ttotal: 7.87s\tremaining: 6.02s\n",
      "85:\tlearn: 0.6947421\ttotal: 7.96s\tremaining: 5.92s\n",
      "86:\tlearn: 0.6932331\ttotal: 8.06s\tremaining: 5.84s\n",
      "87:\tlearn: 0.6920330\ttotal: 8.15s\tremaining: 5.75s\n",
      "88:\tlearn: 0.6907268\ttotal: 8.26s\tremaining: 5.66s\n",
      "89:\tlearn: 0.6896481\ttotal: 8.36s\tremaining: 5.57s\n",
      "90:\tlearn: 0.6884021\ttotal: 8.46s\tremaining: 5.48s\n",
      "91:\tlearn: 0.6873266\ttotal: 8.55s\tremaining: 5.39s\n",
      "92:\tlearn: 0.6858480\ttotal: 8.65s\tremaining: 5.3s\n",
      "93:\tlearn: 0.6846657\ttotal: 8.75s\tremaining: 5.21s\n",
      "94:\tlearn: 0.6838463\ttotal: 8.85s\tremaining: 5.13s\n",
      "95:\tlearn: 0.6828512\ttotal: 8.95s\tremaining: 5.03s\n",
      "96:\tlearn: 0.6816693\ttotal: 9.04s\tremaining: 4.94s\n",
      "97:\tlearn: 0.6806198\ttotal: 9.14s\tremaining: 4.85s\n",
      "98:\tlearn: 0.6793967\ttotal: 9.23s\tremaining: 4.75s\n",
      "99:\tlearn: 0.6782753\ttotal: 9.32s\tremaining: 4.66s\n",
      "100:\tlearn: 0.6771653\ttotal: 9.42s\tremaining: 4.57s\n",
      "101:\tlearn: 0.6759769\ttotal: 9.53s\tremaining: 4.48s\n",
      "102:\tlearn: 0.6753345\ttotal: 9.63s\tremaining: 4.39s\n",
      "103:\tlearn: 0.6746346\ttotal: 9.72s\tremaining: 4.3s\n",
      "104:\tlearn: 0.6735348\ttotal: 9.82s\tremaining: 4.21s\n",
      "105:\tlearn: 0.6728461\ttotal: 9.92s\tremaining: 4.12s\n",
      "106:\tlearn: 0.6714927\ttotal: 10s\tremaining: 4.03s\n",
      "107:\tlearn: 0.6705150\ttotal: 10.1s\tremaining: 3.94s\n",
      "108:\tlearn: 0.6692839\ttotal: 10.2s\tremaining: 3.85s\n",
      "109:\tlearn: 0.6683243\ttotal: 10.3s\tremaining: 3.76s\n",
      "110:\tlearn: 0.6674945\ttotal: 10.4s\tremaining: 3.67s\n",
      "111:\tlearn: 0.6664237\ttotal: 10.5s\tremaining: 3.57s\n",
      "112:\tlearn: 0.6653288\ttotal: 10.6s\tremaining: 3.48s\n",
      "113:\tlearn: 0.6641729\ttotal: 10.7s\tremaining: 3.39s\n",
      "114:\tlearn: 0.6631998\ttotal: 10.8s\tremaining: 3.29s\n",
      "115:\tlearn: 0.6621062\ttotal: 10.9s\tremaining: 3.21s\n",
      "116:\tlearn: 0.6613146\ttotal: 11.1s\tremaining: 3.12s\n",
      "117:\tlearn: 0.6601112\ttotal: 11.2s\tremaining: 3.02s\n",
      "118:\tlearn: 0.6596395\ttotal: 11.3s\tremaining: 2.93s\n",
      "119:\tlearn: 0.6586471\ttotal: 11.4s\tremaining: 2.84s\n",
      "120:\tlearn: 0.6579991\ttotal: 11.4s\tremaining: 2.74s\n",
      "121:\tlearn: 0.6571694\ttotal: 11.5s\tremaining: 2.65s\n",
      "122:\tlearn: 0.6558975\ttotal: 11.6s\tremaining: 2.55s\n",
      "123:\tlearn: 0.6548279\ttotal: 11.7s\tremaining: 2.46s\n",
      "124:\tlearn: 0.6537328\ttotal: 11.8s\tremaining: 2.36s\n",
      "125:\tlearn: 0.6527486\ttotal: 11.9s\tremaining: 2.27s\n",
      "126:\tlearn: 0.6519243\ttotal: 12s\tremaining: 2.17s\n",
      "127:\tlearn: 0.6509050\ttotal: 12.1s\tremaining: 2.08s\n",
      "128:\tlearn: 0.6504250\ttotal: 12.2s\tremaining: 1.99s\n",
      "129:\tlearn: 0.6492354\ttotal: 12.3s\tremaining: 1.89s\n",
      "130:\tlearn: 0.6481583\ttotal: 12.4s\tremaining: 1.8s\n",
      "131:\tlearn: 0.6474572\ttotal: 12.5s\tremaining: 1.7s\n",
      "132:\tlearn: 0.6466005\ttotal: 12.6s\tremaining: 1.61s\n",
      "133:\tlearn: 0.6460656\ttotal: 12.7s\tremaining: 1.51s\n",
      "134:\tlearn: 0.6455235\ttotal: 12.8s\tremaining: 1.42s\n",
      "135:\tlearn: 0.6446670\ttotal: 12.9s\tremaining: 1.32s\n",
      "136:\tlearn: 0.6440868\ttotal: 13s\tremaining: 1.23s\n",
      "137:\tlearn: 0.6431529\ttotal: 13s\tremaining: 1.13s\n",
      "138:\tlearn: 0.6421293\ttotal: 13.1s\tremaining: 1.04s\n",
      "139:\tlearn: 0.6416561\ttotal: 13.3s\tremaining: 947ms\n",
      "140:\tlearn: 0.6411419\ttotal: 13.4s\tremaining: 853ms\n",
      "141:\tlearn: 0.6406801\ttotal: 13.5s\tremaining: 758ms\n",
      "142:\tlearn: 0.6395138\ttotal: 13.6s\tremaining: 664ms\n",
      "143:\tlearn: 0.6389206\ttotal: 13.6s\tremaining: 569ms\n",
      "144:\tlearn: 0.6381038\ttotal: 13.7s\tremaining: 474ms\n",
      "145:\tlearn: 0.6375181\ttotal: 13.9s\tremaining: 381ms\n",
      "146:\tlearn: 0.6367680\ttotal: 14s\tremaining: 286ms\n",
      "147:\tlearn: 0.6357360\ttotal: 14.1s\tremaining: 190ms\n",
      "148:\tlearn: 0.6348665\ttotal: 14.2s\tremaining: 95.2ms\n",
      "149:\tlearn: 0.6340918\ttotal: 14.3s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.601364932016287"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l2_leaf_reg = 3, learning_rate = 0.03, depth = 8, iterations = 150\n",
    "\n",
    "model = CatBoostRegressor(iterations=150, \n",
    "                          depth=8, \n",
    "                          learning_rate=0.03,\n",
    "                          l2_leaf_reg = 3,\n",
    "                          loss_function='RMSE')\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "preds = np.exp(model.predict(X_test))\n",
    "np.sqrt(mean_squared_error(preds, np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dce9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection with random forest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e489c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35669c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1473767",
   "metadata": {},
   "source": [
    "## Train data cleaning and preparation\n",
    "\n",
    "To prepare test, rerun then copy over to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c7e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning everything into floats because apparently we have a whole BUNCH of different types :D\n",
    "train = train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "771941ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing columns with only one value\n",
    "unique = pd.DataFrame(train.nunique())\n",
    "unique.columns = ['unique_count']\n",
    "unique.sort_values(by = 'unique_count',inplace = True)\n",
    "\n",
    "not_unique = list(unique[unique['unique_count'] == 1].reset_index()['index'])\n",
    "train.drop(columns = not_unique, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d1f4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making categorical variables into dummy variables\n",
    "\n",
    "unique.reset_index(inplace = True)\n",
    "unique = unique[unique['unique_count'] != 1]\n",
    "to_cat = unique[unique['unique_count'] <11]\n",
    "dummy_list = list(to_cat['index'])\n",
    "#dummy_list.append('x388')\n",
    "train = pd.get_dummies(train, columns=dummy_list, drop_first=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd2fb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing y and defining X\n",
    "X = train.drop(columns = ['y','id'])\n",
    "y = train['y']\n",
    "cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a65ad3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the skew of y values\n",
    "y = np.log(y)\n",
    "\n",
    "#or don't do until train test split....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df90d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming data that needs to have log taken before scaling (analysis shows basicaly all of them except categorical)\n",
    "alt_list = []\n",
    "for i in X.columns:\n",
    "    if X[i].min() >=0:\n",
    "        if len(i) == 4:\n",
    "            X[i] = X[i] + 1\n",
    "            X[i] = np.log(X[i])\n",
    "            alt_list.append(i)\n",
    "#    else:\n",
    "#        X[i] = X[i] - X[i].min() + 1\n",
    "        \n",
    "#        if len(i) == 4:\n",
    "#            X[i] = np.log(X[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cf769de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = pd.DataFrame(sc.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cdddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using knn to fill in missing values \n",
    "Xknn = KNNImputer(n_neighbors=7).fit(X)\n",
    "X = Xknn.transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78ede740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking which variables are the least normal:\n",
    "#X_copy = X.copy()\n",
    "#X_copy.apply(normaltest, axis=0)\n",
    "#none of them are normal :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "020b5601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.171685</td>\n",
       "      <td>4.655427</td>\n",
       "      <td>-0.271975</td>\n",
       "      <td>9.268671</td>\n",
       "      <td>-2.462688</td>\n",
       "      <td>0.033566</td>\n",
       "      <td>3.896483</td>\n",
       "      <td>-3.467452</td>\n",
       "      <td>-6.164662</td>\n",
       "      <td>-2.011550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062754</td>\n",
       "      <td>0.486073</td>\n",
       "      <td>0.267491</td>\n",
       "      <td>-0.329618</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>-0.471365</td>\n",
       "      <td>-0.550240</td>\n",
       "      <td>-0.262766</td>\n",
       "      <td>-0.335555</td>\n",
       "      <td>-0.047105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-22.195549</td>\n",
       "      <td>2.338399</td>\n",
       "      <td>3.433109</td>\n",
       "      <td>-2.468146</td>\n",
       "      <td>5.625737</td>\n",
       "      <td>9.562394</td>\n",
       "      <td>-1.283923</td>\n",
       "      <td>0.531701</td>\n",
       "      <td>0.223943</td>\n",
       "      <td>0.519484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410901</td>\n",
       "      <td>-0.006818</td>\n",
       "      <td>0.082480</td>\n",
       "      <td>0.207962</td>\n",
       "      <td>-0.217429</td>\n",
       "      <td>-0.402197</td>\n",
       "      <td>-0.049580</td>\n",
       "      <td>0.436941</td>\n",
       "      <td>0.254334</td>\n",
       "      <td>-0.373382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.274904</td>\n",
       "      <td>6.249187</td>\n",
       "      <td>5.059968</td>\n",
       "      <td>-2.792961</td>\n",
       "      <td>-0.425534</td>\n",
       "      <td>4.707002</td>\n",
       "      <td>-6.338027</td>\n",
       "      <td>0.320971</td>\n",
       "      <td>4.249250</td>\n",
       "      <td>1.443158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430309</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>0.204506</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>-0.080999</td>\n",
       "      <td>-0.487166</td>\n",
       "      <td>-0.102832</td>\n",
       "      <td>-0.094962</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>-0.491392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.004339</td>\n",
       "      <td>1.433606</td>\n",
       "      <td>3.327522</td>\n",
       "      <td>-2.959095</td>\n",
       "      <td>-3.400452</td>\n",
       "      <td>-4.695169</td>\n",
       "      <td>3.248549</td>\n",
       "      <td>-2.627271</td>\n",
       "      <td>0.318481</td>\n",
       "      <td>2.630055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199836</td>\n",
       "      <td>-0.052565</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.322863</td>\n",
       "      <td>-0.062802</td>\n",
       "      <td>-0.338914</td>\n",
       "      <td>0.420886</td>\n",
       "      <td>0.156704</td>\n",
       "      <td>0.584764</td>\n",
       "      <td>-0.120253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.059180</td>\n",
       "      <td>1.843585</td>\n",
       "      <td>-1.432763</td>\n",
       "      <td>-6.621450</td>\n",
       "      <td>5.837602</td>\n",
       "      <td>0.396677</td>\n",
       "      <td>-1.313259</td>\n",
       "      <td>7.429804</td>\n",
       "      <td>8.059654</td>\n",
       "      <td>-2.665476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.505669</td>\n",
       "      <td>0.207628</td>\n",
       "      <td>0.600262</td>\n",
       "      <td>-0.389052</td>\n",
       "      <td>0.244643</td>\n",
       "      <td>0.384883</td>\n",
       "      <td>0.031552</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.230703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0  16.171685  4.655427 -0.271975  9.268671 -2.462688  0.033566  3.896483   \n",
       "1 -22.195549  2.338399  3.433109 -2.468146  5.625737  9.562394 -1.283923   \n",
       "2   7.274904  6.249187  5.059968 -2.792961 -0.425534  4.707002 -6.338027   \n",
       "3  -8.004339  1.433606  3.327522 -2.959095 -3.400452 -4.695169  3.248549   \n",
       "4  14.059180  1.843585 -1.432763 -6.621450  5.837602  0.396677 -1.313259   \n",
       "\n",
       "        7         8         9    ...       305       306       307       308  \\\n",
       "0 -3.467452 -6.164662 -2.011550  ...  0.062754  0.486073  0.267491 -0.329618   \n",
       "1  0.531701  0.223943  0.519484  ... -0.410901 -0.006818  0.082480  0.207962   \n",
       "2  0.320971  4.249250  1.443158  ...  0.430309 -0.157851  0.204506  0.007094   \n",
       "3 -2.627271  0.318481  2.630055  ...  0.199836 -0.052565  0.047344  0.322863   \n",
       "4  7.429804  8.059654 -2.665476  ... -0.029541  0.505669  0.207628  0.600262   \n",
       "\n",
       "        309       310       311       312       313       314  \n",
       "0  0.141329 -0.471365 -0.550240 -0.262766 -0.335555 -0.047105  \n",
       "1 -0.217429 -0.402197 -0.049580  0.436941  0.254334 -0.373382  \n",
       "2 -0.080999 -0.487166 -0.102832 -0.094962  0.094186 -0.491392  \n",
       "3 -0.062802 -0.338914  0.420886  0.156704  0.584764 -0.120253  \n",
       "4 -0.389052  0.244643  0.384883  0.031552 -0.007163 -0.230703  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now using PCA to reduce dimensionalitity:\n",
    "pca = PCA(n_components=0.99)\n",
    "pca.fit(X)\n",
    "X_reduced = pd.DataFrame(pca.transform(X))\n",
    "X_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12b5b873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = X_reduced.columns[:50],y = pca.explained_variance_ratio_[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca133a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.6699823 , 11.73764773,  7.35991316,  5.1994689 ,  4.84601532,\n",
       "        2.75538386,  2.14820623,  1.70483673,  1.65643095,  1.25716048,\n",
       "        1.03046563,  0.98579111,  0.94801674,  0.85779464,  0.82422318,\n",
       "        0.72157598,  0.67960845,  0.65889345,  0.62711706,  0.54876619,\n",
       "        0.51031412,  0.49935625,  0.46620211,  0.46322654,  0.44841358,\n",
       "        0.41124485,  0.39802757,  0.38892648,  0.37926812,  0.37264319,\n",
       "        0.36213372,  0.35763477,  0.35405259,  0.34038629,  0.33438798,\n",
       "        0.32673843,  0.32008717,  0.31584802,  0.31006634,  0.30060788,\n",
       "        0.29753642,  0.29339437,  0.29144884,  0.28882104,  0.27909608,\n",
       "        0.27360151,  0.26573932,  0.26496374,  0.26292112,  0.25810896,\n",
       "        0.25395353,  0.24720848,  0.24290595,  0.23848624,  0.23585598,\n",
       "        0.23385094,  0.23251739,  0.22822491,  0.22643286,  0.2242835 ,\n",
       "        0.22337126,  0.21882712,  0.21676488,  0.21162833,  0.20884446,\n",
       "        0.20701634,  0.20287805,  0.20028125,  0.19988201,  0.19793498,\n",
       "        0.19652262,  0.19457814,  0.19239033,  0.19082982,  0.18930216,\n",
       "        0.1860771 ,  0.18301133,  0.18189541,  0.18037875,  0.17770969,\n",
       "        0.17602583,  0.17495867,  0.17398245,  0.17162137,  0.17090351,\n",
       "        0.16786542,  0.16657658,  0.16491238,  0.16226653,  0.16126428,\n",
       "        0.16100141,  0.15932844,  0.15692108,  0.15569361,  0.15528275,\n",
       "        0.15388154,  0.15338548,  0.15177903,  0.15120046,  0.15016317,\n",
       "        0.14958842,  0.148367  ,  0.14750977,  0.1456956 ,  0.14537766,\n",
       "        0.14371507,  0.14201137,  0.14088474,  0.13992933,  0.13871572,\n",
       "        0.13811115,  0.13704988,  0.13667619,  0.13521771,  0.13407113,\n",
       "        0.13364944,  0.13299687,  0.13074333,  0.12954016,  0.12914439,\n",
       "        0.12815124,  0.12712691,  0.12690606,  0.12558099,  0.12472365,\n",
       "        0.12437033,  0.12369887,  0.12317008,  0.12194468,  0.12122961,\n",
       "        0.12021525,  0.11926486,  0.11870818,  0.11709762,  0.11683429,\n",
       "        0.11516081,  0.11509783,  0.11457442,  0.11353838,  0.11336226,\n",
       "        0.11228273,  0.11169861,  0.11073449,  0.11049092,  0.10964814,\n",
       "        0.10897903,  0.10852027,  0.10792719,  0.10759666,  0.10694729,\n",
       "        0.10613615,  0.10493073,  0.10442424,  0.10431847,  0.10377376,\n",
       "        0.10343261,  0.10286492,  0.10248207,  0.10195184,  0.1014967 ,\n",
       "        0.10094427,  0.10012138,  0.09872252,  0.09828463,  0.09736536,\n",
       "        0.0963534 ,  0.09606835,  0.09512298,  0.09467289,  0.09412818,\n",
       "        0.09341317,  0.09291661,  0.09254452,  0.09156979,  0.09106915,\n",
       "        0.09044806,  0.09042395,  0.08976297,  0.08809712,  0.08756664,\n",
       "        0.08731213,  0.08654789,  0.0860024 ,  0.08565677,  0.08504941,\n",
       "        0.08445513,  0.08382837,  0.08303814,  0.08141874,  0.08092271,\n",
       "        0.08019263,  0.07981893,  0.07949703,  0.07874037,  0.07787641,\n",
       "        0.07745932,  0.07657946,  0.0763592 ,  0.07555882,  0.07441941,\n",
       "        0.07392682,  0.07338469,  0.07282674,  0.07210965,  0.07134384,\n",
       "        0.07115586,  0.07015824,  0.06946098,  0.06876873,  0.06827031,\n",
       "        0.06759898,  0.06720923,  0.06667861,  0.06623089,  0.06582251,\n",
       "        0.06487861,  0.06452925,  0.06387125,  0.06321499,  0.06269559,\n",
       "        0.06223377,  0.0618868 ,  0.061118  ,  0.06031984,  0.05989751,\n",
       "        0.05966869,  0.05897865,  0.05869564,  0.05851849,  0.0577873 ,\n",
       "        0.05649417,  0.05590242,  0.05556576,  0.05494338,  0.05414888,\n",
       "        0.05383099,  0.05298735,  0.0524489 ,  0.05172393,  0.05137913,\n",
       "        0.05052057,  0.05033224,  0.04993091,  0.04942885,  0.04905514,\n",
       "        0.04771486,  0.04694697,  0.04654978,  0.04604009,  0.04530681,\n",
       "        0.04484241,  0.04437406,  0.04397855,  0.04342988,  0.04326448,\n",
       "        0.04244944,  0.04184372,  0.04143446,  0.04080945,  0.04052062,\n",
       "        0.03988348,  0.0397437 ,  0.03892149,  0.0387597 ,  0.03814765,\n",
       "        0.03764931,  0.03735957,  0.03657106,  0.03631561,  0.03583032,\n",
       "        0.0357685 ,  0.03522864,  0.0350908 ,  0.03473365,  0.03449212,\n",
       "        0.03366446,  0.03331784,  0.0331788 ,  0.03224756,  0.03191937,\n",
       "        0.0314153 ,  0.03126689,  0.03099246,  0.03032857,  0.02964641,\n",
       "        0.02885627,  0.02828272,  0.02770304,  0.02756446,  0.02736388,\n",
       "        0.02703364,  0.0265869 ,  0.02614855,  0.0250167 ,  0.02458526,\n",
       "        0.02430524,  0.02419897,  0.02405472,  0.02312968,  0.02284323,\n",
       "        0.02250381,  0.02241624,  0.02217402,  0.02181673,  0.02150768,\n",
       "        0.02107674,  0.02067956,  0.02040132,  0.020277  ,  0.01986274,\n",
       "        0.01941803,  0.01921212,  0.01905   ,  0.01853056,  0.01823399])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da5aac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X_reduced.iloc[:,:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a65713",
   "metadata": {},
   "source": [
    "## Downloading the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9bb911c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_reduced,y],axis = 1).to_csv('Cleaned Training Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822596ac",
   "metadata": {},
   "source": [
    "## Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d6164f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_data_official_unmodified.csv')\n",
    "test = test.astype(float)\n",
    "\n",
    "test.drop(columns = not_unique, inplace = True)\n",
    "test = pd.get_dummies(test, columns=dummy_list, drop_first=False)\n",
    "\n",
    "test_ids = test['id']\n",
    "test.drop(columns = 'id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a518433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in alt_list:\n",
    "#    if test[i].min() <0:\n",
    "#        print(i)\n",
    "#checking if we can run the same transformations -- YES\n",
    "\n",
    "for i in alt_list:\n",
    "    #if test[i].min() >=0:\n",
    "    #    if len(i) == 4:\n",
    "    test[i] = test[i] + 1\n",
    "    test[i] = np.log(test[i])\n",
    "            \n",
    "#    else:\n",
    "#        test[i] = test[i] - test[i].min() + 1\n",
    "        \n",
    "#        if len(i) == 4:\n",
    "#            test[i] = np.log(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af447019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4403, 935)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43699925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 935)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7844853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(sc.transform(test))\n",
    "\n",
    "test = KNNImputer(n_neighbors=7).fit_transform(test)\n",
    "test = pd.DataFrame(test)\n",
    "test.columns = cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ba68caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.233831</td>\n",
       "      <td>-8.768771</td>\n",
       "      <td>-3.992604</td>\n",
       "      <td>-5.733440</td>\n",
       "      <td>-2.901199</td>\n",
       "      <td>-0.685093</td>\n",
       "      <td>0.234968</td>\n",
       "      <td>-0.128259</td>\n",
       "      <td>1.269369</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>...</td>\n",
       "      <td>2.446224</td>\n",
       "      <td>-1.787451</td>\n",
       "      <td>2.496151</td>\n",
       "      <td>1.853419</td>\n",
       "      <td>-2.009931</td>\n",
       "      <td>2.350703</td>\n",
       "      <td>-3.635978</td>\n",
       "      <td>-4.002439</td>\n",
       "      <td>2.605719</td>\n",
       "      <td>-0.992652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.788642</td>\n",
       "      <td>16.601554</td>\n",
       "      <td>-4.029642</td>\n",
       "      <td>-10.548207</td>\n",
       "      <td>1.300539</td>\n",
       "      <td>4.984474</td>\n",
       "      <td>6.800707</td>\n",
       "      <td>-0.137442</td>\n",
       "      <td>-6.102906</td>\n",
       "      <td>-4.077643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.735388</td>\n",
       "      <td>2.592583</td>\n",
       "      <td>-2.239645</td>\n",
       "      <td>0.769243</td>\n",
       "      <td>0.564561</td>\n",
       "      <td>-1.364017</td>\n",
       "      <td>2.174120</td>\n",
       "      <td>-1.322109</td>\n",
       "      <td>0.691503</td>\n",
       "      <td>-2.347101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.890173</td>\n",
       "      <td>-0.537095</td>\n",
       "      <td>-2.183489</td>\n",
       "      <td>-3.786984</td>\n",
       "      <td>2.883105</td>\n",
       "      <td>2.528137</td>\n",
       "      <td>1.200961</td>\n",
       "      <td>5.001636</td>\n",
       "      <td>-5.070588</td>\n",
       "      <td>-0.479513</td>\n",
       "      <td>...</td>\n",
       "      <td>6.155962</td>\n",
       "      <td>1.142106</td>\n",
       "      <td>-0.289500</td>\n",
       "      <td>1.626646</td>\n",
       "      <td>6.080880</td>\n",
       "      <td>-2.591491</td>\n",
       "      <td>-0.914738</td>\n",
       "      <td>-0.608334</td>\n",
       "      <td>-1.912322</td>\n",
       "      <td>-1.410289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.013913</td>\n",
       "      <td>5.453337</td>\n",
       "      <td>3.772173</td>\n",
       "      <td>3.403881</td>\n",
       "      <td>7.948616</td>\n",
       "      <td>-8.446196</td>\n",
       "      <td>5.297277</td>\n",
       "      <td>-2.707066</td>\n",
       "      <td>-4.275962</td>\n",
       "      <td>1.857366</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.100813</td>\n",
       "      <td>7.133302</td>\n",
       "      <td>-3.793259</td>\n",
       "      <td>-0.752406</td>\n",
       "      <td>2.715556</td>\n",
       "      <td>1.008248</td>\n",
       "      <td>1.875788</td>\n",
       "      <td>1.015215</td>\n",
       "      <td>2.578869</td>\n",
       "      <td>-0.308305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.646107</td>\n",
       "      <td>3.714199</td>\n",
       "      <td>-0.616606</td>\n",
       "      <td>4.951114</td>\n",
       "      <td>-9.448459</td>\n",
       "      <td>-1.226694</td>\n",
       "      <td>11.453950</td>\n",
       "      <td>-9.565307</td>\n",
       "      <td>1.318037</td>\n",
       "      <td>1.249872</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.268737</td>\n",
       "      <td>8.469160</td>\n",
       "      <td>-14.931760</td>\n",
       "      <td>9.489912</td>\n",
       "      <td>-1.861456</td>\n",
       "      <td>3.899402</td>\n",
       "      <td>-4.966953</td>\n",
       "      <td>6.401872</td>\n",
       "      <td>-2.601540</td>\n",
       "      <td>-0.684006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2          3         4         5          6   \\\n",
       "0  11.233831  -8.768771 -3.992604  -5.733440 -2.901199 -0.685093   0.234968   \n",
       "1  -2.788642  16.601554 -4.029642 -10.548207  1.300539  4.984474   6.800707   \n",
       "2   7.890173  -0.537095 -2.183489  -3.786984  2.883105  2.528137   1.200961   \n",
       "3  14.013913   5.453337  3.772173   3.403881  7.948616 -8.446196   5.297277   \n",
       "4 -14.646107   3.714199 -0.616606   4.951114 -9.448459 -1.226694  11.453950   \n",
       "\n",
       "         7         8         9   ...        12        13         14        15  \\\n",
       "0 -0.128259  1.269369  0.023743  ...  2.446224 -1.787451   2.496151  1.853419   \n",
       "1 -0.137442 -6.102906 -4.077643  ... -0.735388  2.592583  -2.239645  0.769243   \n",
       "2  5.001636 -5.070588 -0.479513  ...  6.155962  1.142106  -0.289500  1.626646   \n",
       "3 -2.707066 -4.275962  1.857366  ... -6.100813  7.133302  -3.793259 -0.752406   \n",
       "4 -9.565307  1.318037  1.249872  ... -3.268737  8.469160 -14.931760  9.489912   \n",
       "\n",
       "         16        17        18        19        20        21  \n",
       "0 -2.009931  2.350703 -3.635978 -4.002439  2.605719 -0.992652  \n",
       "1  0.564561 -1.364017  2.174120 -1.322109  0.691503 -2.347101  \n",
       "2  6.080880 -2.591491 -0.914738 -0.608334 -1.912322 -1.410289  \n",
       "3  2.715556  1.008248  1.875788  1.015215  2.578869 -0.308305  \n",
       "4 -1.861456  3.899402 -4.966953  6.401872 -2.601540 -0.684006  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(pca.transform(test))\n",
    "test = test.iloc[:,:22]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cab967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.171685</td>\n",
       "      <td>4.655427</td>\n",
       "      <td>-0.271975</td>\n",
       "      <td>9.268671</td>\n",
       "      <td>-2.462688</td>\n",
       "      <td>0.033566</td>\n",
       "      <td>3.896483</td>\n",
       "      <td>-3.467452</td>\n",
       "      <td>-6.164662</td>\n",
       "      <td>-2.011550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.940424</td>\n",
       "      <td>7.749418</td>\n",
       "      <td>-8.722531</td>\n",
       "      <td>2.144002</td>\n",
       "      <td>-0.264001</td>\n",
       "      <td>2.066211</td>\n",
       "      <td>1.179680</td>\n",
       "      <td>0.808104</td>\n",
       "      <td>-2.942201</td>\n",
       "      <td>-0.449613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-22.195549</td>\n",
       "      <td>2.338399</td>\n",
       "      <td>3.433109</td>\n",
       "      <td>-2.468146</td>\n",
       "      <td>5.625737</td>\n",
       "      <td>9.562394</td>\n",
       "      <td>-1.283923</td>\n",
       "      <td>0.531701</td>\n",
       "      <td>0.223943</td>\n",
       "      <td>0.519484</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.187116</td>\n",
       "      <td>1.774034</td>\n",
       "      <td>4.024381</td>\n",
       "      <td>-0.861666</td>\n",
       "      <td>-1.988013</td>\n",
       "      <td>-1.525865</td>\n",
       "      <td>0.439872</td>\n",
       "      <td>-1.788450</td>\n",
       "      <td>-0.337937</td>\n",
       "      <td>2.445422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.274904</td>\n",
       "      <td>6.249187</td>\n",
       "      <td>5.059968</td>\n",
       "      <td>-2.792961</td>\n",
       "      <td>-0.425534</td>\n",
       "      <td>4.707002</td>\n",
       "      <td>-6.338027</td>\n",
       "      <td>0.320971</td>\n",
       "      <td>4.249250</td>\n",
       "      <td>1.443158</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.222713</td>\n",
       "      <td>-0.680347</td>\n",
       "      <td>-1.908036</td>\n",
       "      <td>1.857109</td>\n",
       "      <td>-1.768565</td>\n",
       "      <td>-1.220775</td>\n",
       "      <td>1.081026</td>\n",
       "      <td>-4.160032</td>\n",
       "      <td>-6.140138</td>\n",
       "      <td>0.342577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.004339</td>\n",
       "      <td>1.433606</td>\n",
       "      <td>3.327522</td>\n",
       "      <td>-2.959095</td>\n",
       "      <td>-3.400452</td>\n",
       "      <td>-4.695169</td>\n",
       "      <td>3.248549</td>\n",
       "      <td>-2.627271</td>\n",
       "      <td>0.318481</td>\n",
       "      <td>2.630055</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.243377</td>\n",
       "      <td>3.574798</td>\n",
       "      <td>0.990902</td>\n",
       "      <td>-1.521911</td>\n",
       "      <td>-0.111404</td>\n",
       "      <td>-4.182897</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>-0.414162</td>\n",
       "      <td>1.149719</td>\n",
       "      <td>1.896762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.059180</td>\n",
       "      <td>1.843585</td>\n",
       "      <td>-1.432763</td>\n",
       "      <td>-6.621450</td>\n",
       "      <td>5.837602</td>\n",
       "      <td>0.396677</td>\n",
       "      <td>-1.313259</td>\n",
       "      <td>7.429804</td>\n",
       "      <td>8.059654</td>\n",
       "      <td>-2.665476</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.947321</td>\n",
       "      <td>-1.514235</td>\n",
       "      <td>-0.338053</td>\n",
       "      <td>-3.089166</td>\n",
       "      <td>-6.071536</td>\n",
       "      <td>3.202410</td>\n",
       "      <td>0.803484</td>\n",
       "      <td>0.146411</td>\n",
       "      <td>1.149635</td>\n",
       "      <td>2.432319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  16.171685  4.655427 -0.271975  9.268671 -2.462688  0.033566  3.896483   \n",
       "1 -22.195549  2.338399  3.433109 -2.468146  5.625737  9.562394 -1.283923   \n",
       "2   7.274904  6.249187  5.059968 -2.792961 -0.425534  4.707002 -6.338027   \n",
       "3  -8.004339  1.433606  3.327522 -2.959095 -3.400452 -4.695169  3.248549   \n",
       "4  14.059180  1.843585 -1.432763 -6.621450  5.837602  0.396677 -1.313259   \n",
       "\n",
       "         7         8         9   ...        12        13        14        15  \\\n",
       "0 -3.467452 -6.164662 -2.011550  ... -1.940424  7.749418 -8.722531  2.144002   \n",
       "1  0.531701  0.223943  0.519484  ... -3.187116  1.774034  4.024381 -0.861666   \n",
       "2  0.320971  4.249250  1.443158  ... -2.222713 -0.680347 -1.908036  1.857109   \n",
       "3 -2.627271  0.318481  2.630055  ... -3.243377  3.574798  0.990902 -1.521911   \n",
       "4  7.429804  8.059654 -2.665476  ... -2.947321 -1.514235 -0.338053 -3.089166   \n",
       "\n",
       "         16        17        18        19        20        21  \n",
       "0 -0.264001  2.066211  1.179680  0.808104 -2.942201 -0.449613  \n",
       "1 -1.988013 -1.525865  0.439872 -1.788450 -0.337937  2.445422  \n",
       "2 -1.768565 -1.220775  1.081026 -4.160032 -6.140138  0.342577  \n",
       "3 -0.111404 -4.182897  0.027678 -0.414162  1.149719  1.896762  \n",
       "4 -6.071536  3.202410  0.803484  0.146411  1.149635  2.432319  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d9e2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't forget to add the ids and np.exp the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3f4ef",
   "metadata": {},
   "source": [
    "## Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b4a9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_reduced = pd.read_csv('Cleaned Training Data.csv')\n",
    "#y = X_reduced['y']\n",
    "#X_reduced.drop(columns = 'y',inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#y_train, y_test have the log taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a6cb7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.171685</td>\n",
       "      <td>4.655427</td>\n",
       "      <td>-0.271975</td>\n",
       "      <td>9.268671</td>\n",
       "      <td>-2.462688</td>\n",
       "      <td>0.033566</td>\n",
       "      <td>3.896483</td>\n",
       "      <td>-3.467452</td>\n",
       "      <td>-6.164662</td>\n",
       "      <td>-2.011550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062754</td>\n",
       "      <td>0.486073</td>\n",
       "      <td>0.267491</td>\n",
       "      <td>-0.329618</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>-0.471365</td>\n",
       "      <td>-0.550240</td>\n",
       "      <td>-0.262766</td>\n",
       "      <td>-0.335555</td>\n",
       "      <td>-0.047105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-22.195549</td>\n",
       "      <td>2.338399</td>\n",
       "      <td>3.433109</td>\n",
       "      <td>-2.468146</td>\n",
       "      <td>5.625737</td>\n",
       "      <td>9.562394</td>\n",
       "      <td>-1.283923</td>\n",
       "      <td>0.531701</td>\n",
       "      <td>0.223943</td>\n",
       "      <td>0.519484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410901</td>\n",
       "      <td>-0.006818</td>\n",
       "      <td>0.082480</td>\n",
       "      <td>0.207962</td>\n",
       "      <td>-0.217429</td>\n",
       "      <td>-0.402197</td>\n",
       "      <td>-0.049580</td>\n",
       "      <td>0.436941</td>\n",
       "      <td>0.254334</td>\n",
       "      <td>-0.373382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.274904</td>\n",
       "      <td>6.249187</td>\n",
       "      <td>5.059968</td>\n",
       "      <td>-2.792961</td>\n",
       "      <td>-0.425534</td>\n",
       "      <td>4.707002</td>\n",
       "      <td>-6.338027</td>\n",
       "      <td>0.320971</td>\n",
       "      <td>4.249250</td>\n",
       "      <td>1.443158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430309</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>0.204506</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>-0.080999</td>\n",
       "      <td>-0.487166</td>\n",
       "      <td>-0.102832</td>\n",
       "      <td>-0.094962</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>-0.491392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.004339</td>\n",
       "      <td>1.433606</td>\n",
       "      <td>3.327522</td>\n",
       "      <td>-2.959095</td>\n",
       "      <td>-3.400452</td>\n",
       "      <td>-4.695169</td>\n",
       "      <td>3.248549</td>\n",
       "      <td>-2.627271</td>\n",
       "      <td>0.318481</td>\n",
       "      <td>2.630055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199836</td>\n",
       "      <td>-0.052565</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.322863</td>\n",
       "      <td>-0.062802</td>\n",
       "      <td>-0.338914</td>\n",
       "      <td>0.420886</td>\n",
       "      <td>0.156704</td>\n",
       "      <td>0.584764</td>\n",
       "      <td>-0.120253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.059180</td>\n",
       "      <td>1.843585</td>\n",
       "      <td>-1.432763</td>\n",
       "      <td>-6.621450</td>\n",
       "      <td>5.837602</td>\n",
       "      <td>0.396677</td>\n",
       "      <td>-1.313259</td>\n",
       "      <td>7.429804</td>\n",
       "      <td>8.059654</td>\n",
       "      <td>-2.665476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.505669</td>\n",
       "      <td>0.207628</td>\n",
       "      <td>0.600262</td>\n",
       "      <td>-0.389052</td>\n",
       "      <td>0.244643</td>\n",
       "      <td>0.384883</td>\n",
       "      <td>0.031552</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.230703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>-2.244083</td>\n",
       "      <td>14.867143</td>\n",
       "      <td>10.420017</td>\n",
       "      <td>-2.655767</td>\n",
       "      <td>-11.664750</td>\n",
       "      <td>-5.978020</td>\n",
       "      <td>3.504145</td>\n",
       "      <td>-5.359213</td>\n",
       "      <td>1.706159</td>\n",
       "      <td>-2.600509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>-0.138454</td>\n",
       "      <td>0.082889</td>\n",
       "      <td>-0.230490</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>-0.437614</td>\n",
       "      <td>0.221602</td>\n",
       "      <td>-0.028672</td>\n",
       "      <td>-0.159745</td>\n",
       "      <td>0.618227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>12.939071</td>\n",
       "      <td>-4.491801</td>\n",
       "      <td>10.572567</td>\n",
       "      <td>-4.518676</td>\n",
       "      <td>-4.157038</td>\n",
       "      <td>-1.654457</td>\n",
       "      <td>0.541173</td>\n",
       "      <td>-1.703279</td>\n",
       "      <td>-1.792376</td>\n",
       "      <td>-2.416812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058349</td>\n",
       "      <td>0.050566</td>\n",
       "      <td>0.331031</td>\n",
       "      <td>0.312992</td>\n",
       "      <td>-0.376803</td>\n",
       "      <td>-0.321890</td>\n",
       "      <td>-0.549241</td>\n",
       "      <td>0.235627</td>\n",
       "      <td>0.279166</td>\n",
       "      <td>-0.062629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>3.352022</td>\n",
       "      <td>7.325950</td>\n",
       "      <td>15.720106</td>\n",
       "      <td>0.658067</td>\n",
       "      <td>4.637985</td>\n",
       "      <td>-0.265182</td>\n",
       "      <td>-4.074616</td>\n",
       "      <td>4.395005</td>\n",
       "      <td>-3.176817</td>\n",
       "      <td>-4.239738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077841</td>\n",
       "      <td>-0.509483</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>-0.050955</td>\n",
       "      <td>-0.047959</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>-0.087067</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>-0.031184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>14.548006</td>\n",
       "      <td>-1.587547</td>\n",
       "      <td>-9.642746</td>\n",
       "      <td>-9.006445</td>\n",
       "      <td>-6.769682</td>\n",
       "      <td>0.684489</td>\n",
       "      <td>1.160844</td>\n",
       "      <td>-0.294789</td>\n",
       "      <td>-2.591597</td>\n",
       "      <td>-1.078066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.250156</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>-0.042820</td>\n",
       "      <td>-0.506369</td>\n",
       "      <td>-0.156495</td>\n",
       "      <td>-0.073128</td>\n",
       "      <td>0.235496</td>\n",
       "      <td>-0.277897</td>\n",
       "      <td>0.344253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>-10.163572</td>\n",
       "      <td>19.260942</td>\n",
       "      <td>-9.008484</td>\n",
       "      <td>-6.567436</td>\n",
       "      <td>-11.175644</td>\n",
       "      <td>-6.826458</td>\n",
       "      <td>-3.296996</td>\n",
       "      <td>-3.411992</td>\n",
       "      <td>4.058962</td>\n",
       "      <td>-0.471592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463812</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>-1.277609</td>\n",
       "      <td>-0.457690</td>\n",
       "      <td>0.024753</td>\n",
       "      <td>0.241709</td>\n",
       "      <td>-0.845020</td>\n",
       "      <td>-0.301652</td>\n",
       "      <td>-0.341191</td>\n",
       "      <td>-0.358782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2         3          4         5    \\\n",
       "0     16.171685   4.655427  -0.271975  9.268671  -2.462688  0.033566   \n",
       "1    -22.195549   2.338399   3.433109 -2.468146   5.625737  9.562394   \n",
       "2      7.274904   6.249187   5.059968 -2.792961  -0.425534  4.707002   \n",
       "3     -8.004339   1.433606   3.327522 -2.959095  -3.400452 -4.695169   \n",
       "4     14.059180   1.843585  -1.432763 -6.621450   5.837602  0.396677   \n",
       "...         ...        ...        ...       ...        ...       ...   \n",
       "5375  -2.244083  14.867143  10.420017 -2.655767 -11.664750 -5.978020   \n",
       "5376  12.939071  -4.491801  10.572567 -4.518676  -4.157038 -1.654457   \n",
       "5377   3.352022   7.325950  15.720106  0.658067   4.637985 -0.265182   \n",
       "5378  14.548006  -1.587547  -9.642746 -9.006445  -6.769682  0.684489   \n",
       "5379 -10.163572  19.260942  -9.008484 -6.567436 -11.175644 -6.826458   \n",
       "\n",
       "           6         7         8         9    ...       305       306  \\\n",
       "0     3.896483 -3.467452 -6.164662 -2.011550  ...  0.062754  0.486073   \n",
       "1    -1.283923  0.531701  0.223943  0.519484  ... -0.410901 -0.006818   \n",
       "2    -6.338027  0.320971  4.249250  1.443158  ...  0.430309 -0.157851   \n",
       "3     3.248549 -2.627271  0.318481  2.630055  ...  0.199836 -0.052565   \n",
       "4    -1.313259  7.429804  8.059654 -2.665476  ... -0.029541  0.505669   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "5375  3.504145 -5.359213  1.706159 -2.600509  ...  0.188034 -0.138454   \n",
       "5376  0.541173 -1.703279 -1.792376 -2.416812  ... -0.058349  0.050566   \n",
       "5377 -4.074616  4.395005 -3.176817 -4.239738  ... -0.077841 -0.509483   \n",
       "5378  1.160844 -0.294789 -2.591597 -1.078066  ... -0.004365  0.250156   \n",
       "5379 -3.296996 -3.411992  4.058962 -0.471592  ...  0.463812 -0.166786   \n",
       "\n",
       "           307       308       309       310       311       312       313  \\\n",
       "0     0.267491 -0.329618  0.141329 -0.471365 -0.550240 -0.262766 -0.335555   \n",
       "1     0.082480  0.207962 -0.217429 -0.402197 -0.049580  0.436941  0.254334   \n",
       "2     0.204506  0.007094 -0.080999 -0.487166 -0.102832 -0.094962  0.094186   \n",
       "3     0.047344  0.322863 -0.062802 -0.338914  0.420886  0.156704  0.584764   \n",
       "4     0.207628  0.600262 -0.389052  0.244643  0.384883  0.031552 -0.007163   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5375  0.082889 -0.230490  0.091912 -0.437614  0.221602 -0.028672 -0.159745   \n",
       "5376  0.331031  0.312992 -0.376803 -0.321890 -0.549241  0.235627  0.279166   \n",
       "5377 -0.474839 -0.050955 -0.047959  0.615375 -0.087067  0.014270  0.084629   \n",
       "5378  0.025607 -0.042820 -0.506369 -0.156495 -0.073128  0.235496 -0.277897   \n",
       "5379 -1.277609 -0.457690  0.024753  0.241709 -0.845020 -0.301652 -0.341191   \n",
       "\n",
       "           314  \n",
       "0    -0.047105  \n",
       "1    -0.373382  \n",
       "2    -0.491392  \n",
       "3    -0.120253  \n",
       "4    -0.230703  \n",
       "...        ...  \n",
       "5375  0.618227  \n",
       "5376 -0.062629  \n",
       "5377 -0.031184  \n",
       "5378  0.344253  \n",
       "5379 -0.358782  \n",
       "\n",
       "[5380 rows x 315 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b5c0f",
   "metadata": {},
   "source": [
    "## Predicting on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a383f2",
   "metadata": {},
   "source": [
    "Could train models on two different random state splits and then average the two???!?!??!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fdf47dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7.326557\n",
       "1        7.403814\n",
       "2        4.360031\n",
       "3        6.019714\n",
       "4        3.798332\n",
       "          ...    \n",
       "4398     3.678809\n",
       "4399    10.201312\n",
       "4400     8.602595\n",
       "4401     6.109168\n",
       "4402    16.487177\n",
       "Name: 0, Length: 4403, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_test = LinearRegression().fit(X_train,y_train)\n",
    "preds = lin_test.predict(test)\n",
    "\n",
    "\n",
    "#preds = np.exp(preds)\n",
    "preds = pd.DataFrame(preds)[0].apply(lambda x: 4.605 if x > 4.605 else x)\n",
    "preds = np.exp(preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efb48aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2141    4.60517\n",
       "3810    4.60517\n",
       "1187    4.60517\n",
       "4041    4.60517\n",
       "1829    4.60517\n",
       "         ...   \n",
       "534     0.00000\n",
       "532     0.00000\n",
       "4537    0.00000\n",
       "2873    0.00000\n",
       "3700    0.00000\n",
       "Name: y, Length: 5380, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25b281f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.605170185988092"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfd9a646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.511293290691075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random = 42\n",
    "lin_test = LinearRegression().fit(X_train,y_train)\n",
    "preds = lin_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))\n",
    "\n",
    "#pd.DataFrame(preds).sort_values(ascending = False, by = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b501dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.821262418427631"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random =0\n",
    "lin_test = LinearRegression().fit(X_train,y_train)\n",
    "preds = lin_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bbf906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01071447, 0.01201507, 0.00266649, 0.00350129, 0.02212542,\n",
       "       0.0052819 , 0.00099021, 0.00976015, 0.00492001, 0.00329247,\n",
       "       0.00803829, 0.00176871, 0.00414716, 0.00516119, 0.00498657,\n",
       "       0.0097902 , 0.0023244 , 0.00437151, 0.00992669, 0.00284598,\n",
       "       0.00361653, 0.00472212, 0.00777579, 0.00155346, 0.00212649,\n",
       "       0.00154149, 0.00334244, 0.00315039, 0.00281973, 0.00558391,\n",
       "       0.00413647, 0.00342293, 0.00174229, 0.0021691 , 0.00349791,\n",
       "       0.0026819 , 0.00387675, 0.00379573, 0.00248849, 0.00335356,\n",
       "       0.00279956, 0.00334228, 0.00353165, 0.0025193 , 0.00240819,\n",
       "       0.00365185, 0.00316812, 0.00173707, 0.00266602, 0.00613521,\n",
       "       0.00167826, 0.00276981, 0.00429354, 0.00479295, 0.00195212,\n",
       "       0.00221803, 0.00350355, 0.00219259, 0.0023011 , 0.00401116,\n",
       "       0.00227058, 0.00449549, 0.00317217, 0.00391494, 0.00253597,\n",
       "       0.0017127 , 0.00273908, 0.00472131, 0.00307628, 0.00334212,\n",
       "       0.00228504, 0.00387881, 0.00312042, 0.00345455, 0.0021031 ,\n",
       "       0.0036129 , 0.00262788, 0.        , 0.00407097, 0.00208302,\n",
       "       0.00337829, 0.00309408, 0.00185002, 0.00214182, 0.00284652,\n",
       "       0.00318978, 0.00301813, 0.00366993, 0.00345172, 0.00385257,\n",
       "       0.00232392, 0.00210215, 0.00298023, 0.00229178, 0.00219725,\n",
       "       0.00208015, 0.00207297, 0.00283099, 0.00360153, 0.00355974,\n",
       "       0.002886  , 0.00201813, 0.00249663, 0.00261415, 0.00280424,\n",
       "       0.00180888, 0.00276309, 0.00254109, 0.00146345, 0.00355439,\n",
       "       0.00203778, 0.00383534, 0.00182899, 0.0019514 , 0.00299986,\n",
       "       0.00298334, 0.0015417 , 0.00298235, 0.00336434, 0.00231722,\n",
       "       0.00304213, 0.        , 0.00630759, 0.00218731, 0.00216727,\n",
       "       0.00453987, 0.00223877, 0.00338375, 0.00280589, 0.00195476,\n",
       "       0.00186541, 0.00243876, 0.00329523, 0.00435146, 0.00380818,\n",
       "       0.00333826, 0.0025063 , 0.00274891, 0.0028521 , 0.00237492,\n",
       "       0.00242423, 0.00231418, 0.00328455, 0.0020278 , 0.00296169,\n",
       "       0.0027302 , 0.00428837, 0.00286957, 0.00293405, 0.00190353,\n",
       "       0.00271304, 0.00272329, 0.00315581, 0.00316403, 0.00264459,\n",
       "       0.00294062, 0.00382903, 0.00190227, 0.00282496, 0.00242751,\n",
       "       0.00234181, 0.00296669, 0.00417718, 0.00351665, 0.00183316,\n",
       "       0.00216627, 0.00147584, 0.00349695, 0.00135695, 0.00209486,\n",
       "       0.00311704, 0.00211097, 0.00604054, 0.00278638, 0.0019136 ,\n",
       "       0.00202363, 0.00326078, 0.00329158, 0.00341847, 0.00237058,\n",
       "       0.00392757, 0.00272946, 0.00238177, 0.00296209, 0.0030972 ,\n",
       "       0.00272636, 0.00296082, 0.00300258, 0.00331681, 0.00228036,\n",
       "       0.00304687, 0.00446212, 0.00305513, 0.00352556, 0.0022672 ,\n",
       "       0.00259566, 0.00248063, 0.001608  , 0.00306757, 0.00237812,\n",
       "       0.00319929, 0.00242488, 0.0023751 , 0.00314705, 0.00328462,\n",
       "       0.00255054, 0.00228538, 0.00269197, 0.00327189, 0.00269119,\n",
       "       0.00192007, 0.00273535, 0.00147846, 0.00340177, 0.00148866,\n",
       "       0.00360387, 0.0030487 , 0.00344973, 0.00358999, 0.00326826,\n",
       "       0.00182698, 0.00264273, 0.00263524, 0.00245992, 0.00269265,\n",
       "       0.00325565, 0.0049363 , 0.00390959, 0.0039539 , 0.00300782,\n",
       "       0.00457333, 0.00360333, 0.00143625, 0.0037119 , 0.0024147 ,\n",
       "       0.00228253, 0.00340905, 0.00668946, 0.00330375, 0.00187951,\n",
       "       0.0036036 , 0.00308711, 0.00235829, 0.00335118, 0.00298646,\n",
       "       0.00280521, 0.00388772, 0.        , 0.00375127, 0.00193347,\n",
       "       0.00277174, 0.00168616, 0.00434035, 0.00347457, 0.00152242,\n",
       "       0.00334444, 0.00255902, 0.00256485, 0.00291015, 0.0036031 ,\n",
       "       0.00354559, 0.00240519, 0.00478177, 0.00203787, 0.0028428 ,\n",
       "       0.00653367, 0.00223464, 0.00329757, 0.00176542, 0.00503278,\n",
       "       0.00216225, 0.00244926, 0.0022092 , 0.00161954, 0.00281307,\n",
       "       0.00300749, 0.0014249 , 0.00286589, 0.00397087, 0.00228327,\n",
       "       0.0040683 , 0.00395375, 0.00335577, 0.00418025, 0.00319158,\n",
       "       0.00317765, 0.00451694, 0.00312683, 0.00368062, 0.00412365,\n",
       "       0.00194033, 0.00265618, 0.00231077, 0.00384833, 0.00410115,\n",
       "       0.00424584, 0.00343936, 0.00313937, 0.00228262, 0.00208912,\n",
       "       0.        , 0.00452226, 0.00414205, 0.00033198, 0.0020173 ,\n",
       "       0.00241024, 0.00283584, 0.00284859, 0.00466963, 0.00219655,\n",
       "       0.00353983, 0.00427113, 0.00300023, 0.00497711, 0.00231004],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None).fit(X_train,y_train)\n",
    "\n",
    "xgb_test.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "869f19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_test.feature_importances_\n",
    "importances = {'column':X_train.columns,'importance':importances}\n",
    "importances = pd.DataFrame(importances)\n",
    "xgb_most_important_cols = list(importances.sort_values(by = 'importance', ascending = False)[:100]['column'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b12ee83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.344329061614994"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not big difference between using most important columns and all columns\n",
    "xgb_test = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None).fit(X_train[xgb_most_important_cols],y_train)\n",
    "\n",
    "\n",
    "preds = xgb_test.predict(X_test[xgb_most_important_cols])\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd81b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db32fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afe73d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.950490758028096"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test = RandomForestRegressor(max_depth = 15, max_features = 16,min_samples_leaf=5,min_samples_split=3).fit(X_train,y_train)\n",
    "preds = rf_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea55c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8a4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25ab67f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.809096951084682"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {'base_estimator': [DecisionTreeRegressor(random_state =1),LinearRegression()],\n",
    "          'n_estimators': [200,250,400,600,800],\n",
    "          'max_samples': [0.25,0.5,0.75],\n",
    "          'max_features': [0.5,0.75],\n",
    "          'bootstrap': [True, False],\n",
    "          'bootstrap_features': [True, False]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "bagging_regressor_grid = GridSearchCV(BaggingRegressor(random_state=1,n_jobs=-1),\n",
    "                                      param_grid =params, cv=cv, n_jobs=-1,\n",
    "                                      verbose=1, scoring = 'neg_root_mean_squared_error')\n",
    "bagging_regressor_grid.fit(X_train, y_train)\n",
    "\n",
    "bagging_regressor_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86dd549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=LinearRegression(), bootstrap=False,\n",
       "                 max_features=0.75, max_samples=0.25, n_estimators=250,\n",
       "                 n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_regressor_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e8fe8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.979215003647175"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bag_model = BaggingRegressor(base_estimator=LinearRegression(),n_estimators=250,\n",
    "                             max_samples = 0.25,\n",
    "                             max_features = 0.75,\n",
    "                             bootstrap = False,\n",
    "                             random_state=1,n_jobs=-1).fit(X_train, y_train)\n",
    "preds = bag_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6253a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d34ecd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arielle\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:813: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "C:\\Users\\Arielle\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:1066: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.934095713131013"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#earth_params= {'max_degree':[1,2,3],\n",
    "#              'max_terms':[200,300,400]}\n",
    "\n",
    "#cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "#MARS_grid = GridSearchCV(Earth(),\n",
    "#                         param_grid =earth_params, cv=cv, n_jobs=-1,\n",
    " #                        verbose=1, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "#MARS_grid.fit(X_train, y_train)\n",
    "\n",
    "#MARS.best_score_\n",
    "\n",
    "mars_model = Earth(max_degree=2,max_terms=300).fit(X_train,y_train)\n",
    "\n",
    "preds = mars_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a481eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4304, 315)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36d6db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 4.9262 - val_loss: 4.0651\n",
      "Epoch 2/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 4.2980 - val_loss: 3.7559\n",
      "Epoch 3/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.9846 - val_loss: 3.6047\n",
      "Epoch 4/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.7814 - val_loss: 3.5125\n",
      "Epoch 5/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.6581 - val_loss: 3.4341\n",
      "Epoch 6/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.5549 - val_loss: 3.3593\n",
      "Epoch 7/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.4551 - val_loss: 3.2886\n",
      "Epoch 8/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.3714 - val_loss: 3.2167\n",
      "Epoch 9/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.2879 - val_loss: 3.1405\n",
      "Epoch 10/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.2035 - val_loss: 3.0549\n",
      "Epoch 11/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 3.1069 - val_loss: 2.9601\n",
      "Epoch 12/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.9964 - val_loss: 2.8499\n",
      "Epoch 13/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.8768 - val_loss: 2.7171\n",
      "Epoch 14/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.7161 - val_loss: 2.5388\n",
      "Epoch 15/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.5053 - val_loss: 2.2953\n",
      "Epoch 16/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.2196 - val_loss: 1.9712\n",
      "Epoch 17/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.8747 - val_loss: 1.5925\n",
      "Epoch 18/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.5247 - val_loss: 1.2858\n",
      "Epoch 19/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.3439 - val_loss: 1.1327\n",
      "Epoch 20/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.2563 - val_loss: 1.0541\n",
      "Epoch 21/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.1552 - val_loss: 1.0009\n",
      "Epoch 22/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.1609 - val_loss: 0.9536\n",
      "Epoch 23/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.0953 - val_loss: 0.9320\n",
      "Epoch 24/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.0279 - val_loss: 0.8938\n",
      "Epoch 25/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.0246 - val_loss: 0.8801\n",
      "Epoch 26/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9879 - val_loss: 0.8670\n",
      "Epoch 27/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9564 - val_loss: 0.8555\n",
      "Epoch 28/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9064 - val_loss: 0.8384\n",
      "Epoch 29/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.8219\n",
      "Epoch 30/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8943 - val_loss: 0.8138\n",
      "Epoch 31/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8603 - val_loss: 0.8009\n",
      "Epoch 32/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8548 - val_loss: 0.7916\n",
      "Epoch 33/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8267 - val_loss: 0.7840\n",
      "Epoch 34/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8064 - val_loss: 0.7816\n",
      "Epoch 35/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8073 - val_loss: 0.7751\n",
      "Epoch 36/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7996 - val_loss: 0.7717\n",
      "Epoch 37/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7660 - val_loss: 0.7599\n",
      "Epoch 38/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7787 - val_loss: 0.7587\n",
      "Epoch 39/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7496 - val_loss: 0.7545\n",
      "Epoch 40/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7375 - val_loss: 0.7499\n",
      "Epoch 41/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7314 - val_loss: 0.7472\n",
      "Epoch 42/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7072 - val_loss: 0.7400\n",
      "Epoch 43/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7002 - val_loss: 0.7364\n",
      "Epoch 44/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6957 - val_loss: 0.7308\n",
      "Epoch 45/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 0.7265\n",
      "Epoch 46/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6682 - val_loss: 0.7282\n",
      "Epoch 47/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6732 - val_loss: 0.7255\n",
      "Epoch 48/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6437 - val_loss: 0.7168\n",
      "Epoch 49/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.7250\n",
      "Epoch 50/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6555 - val_loss: 0.7228\n",
      "Epoch 51/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6581 - val_loss: 0.7257\n",
      "Epoch 52/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6378 - val_loss: 0.7097\n",
      "Epoch 53/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.7059\n",
      "Epoch 54/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.7071\n",
      "Epoch 55/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.7088\n",
      "Epoch 56/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.7048\n",
      "Epoch 57/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.7039\n",
      "Epoch 58/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.7030\n",
      "Epoch 59/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 0.7105\n",
      "Epoch 60/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.7032\n",
      "Epoch 61/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5782 - val_loss: 0.6984\n",
      "Epoch 62/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5921 - val_loss: 0.6965\n",
      "Epoch 63/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5936 - val_loss: 0.7003\n",
      "Epoch 64/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5932 - val_loss: 0.7026\n",
      "Epoch 65/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5881 - val_loss: 0.7012\n",
      "Epoch 66/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5584 - val_loss: 0.6903\n",
      "Epoch 67/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5719 - val_loss: 0.6950\n",
      "Epoch 68/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5539 - val_loss: 0.6994\n",
      "Epoch 69/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 0.7002\n",
      "Epoch 70/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5698 - val_loss: 0.6953\n",
      "Epoch 71/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5625 - val_loss: 0.6912\n",
      "Epoch 72/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5533 - val_loss: 0.6981\n",
      "Epoch 73/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.6907\n",
      "Epoch 74/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.6888\n",
      "Epoch 75/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 0.6929\n",
      "Epoch 76/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.6891\n",
      "Epoch 77/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.6922\n",
      "Epoch 78/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 0.7019\n",
      "Epoch 79/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.6918\n",
      "Epoch 80/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 0.6971\n",
      "Epoch 81/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.6937\n",
      "Epoch 82/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 0.6921\n",
      "Epoch 83/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.6888\n",
      "Epoch 84/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.6862\n",
      "Epoch 85/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.6830\n",
      "Epoch 86/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.6921\n",
      "Epoch 87/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.6837\n",
      "Epoch 88/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.6837\n",
      "Epoch 89/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.6887\n",
      "Epoch 90/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.6948\n",
      "Epoch 91/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 0.6931\n",
      "Epoch 92/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.6871\n",
      "Epoch 93/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.6929\n",
      "Epoch 94/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.6981\n",
      "Epoch 95/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.6799\n",
      "Epoch 96/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.6947\n",
      "Epoch 97/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.6875\n",
      "Epoch 98/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.6927\n",
      "Epoch 99/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.6927\n",
      "Epoch 100/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.6887\n",
      "Epoch 101/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.6864\n",
      "Epoch 102/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6875\n",
      "Epoch 103/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6960\n",
      "Epoch 104/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.6853\n",
      "Epoch 105/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.6962\n",
      "Epoch 106/500\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.4428 - val_loss: 0.6884\n",
      "Epoch 107/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6893\n",
      "Epoch 108/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 0.6938\n",
      "Epoch 109/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.6948\n",
      "Epoch 110/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.6956\n",
      "Epoch 111/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.6981\n",
      "Epoch 112/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.6876\n",
      "Epoch 113/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.6966\n",
      "Epoch 114/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4194 - val_loss: 0.6994\n",
      "Epoch 115/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.6980\n",
      "10.657633852721435\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer #inputlayer is the input nodes definition, dense is a fully connected layer\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "network = Sequential() #this creates an empty network for you to add to \n",
    "\n",
    "network.add(InputLayer(input_shape = (X_train.shape[1], ))) \n",
    "\n",
    "network.add(Dense(20, activation = 'relu')) \n",
    "network.add(Dropout(0.1))\n",
    "network.add(Dense(18, activation = 'relu')) \n",
    "network.add(Dropout(0.1))\n",
    "network.add(Dense(16, activation = 'relu')) \n",
    "network.add(Dropout(0.2))\n",
    "network.add(Dense(15, activation = 'relu')) \n",
    "network.add(Dropout(0.2))\n",
    "network.add(Dense(13, activation = 'relu')) \n",
    "\n",
    "network.add(Dense(10, activation = 'relu')) \n",
    "\n",
    "\n",
    "network.add(Dense(5, activation = 'relu'))\n",
    "network.add(Dense(1, activation = 'linear')) #this is the output layer!\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "network.compile(optimizer = optimizer,loss = 'mean_squared_error') \n",
    "\n",
    "early = EarlyStopping('val_loss', patience = 20) \n",
    "\n",
    "history = network.fit(X_train,y_train,epochs =500,batch_size=50,validation_split = 0.2, callbacks = early) \n",
    "\n",
    "\n",
    "\n",
    "preds = network.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test))))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','val'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2fada64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758aa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0312b6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.7572895600360996"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_test = LinearRegression()\n",
    "SVR_test = SVR(C=1)\n",
    "xgb_test = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('lr', lin_test),\n",
    "    ('svr', SVR_test),\n",
    "    ('xgb',xgb_test),\n",
    "    ('rand',bag_test)]\n",
    "\n",
    "\n",
    "\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators\n",
    "    #final_estimator=RandomForestRegressor(n_estimators=10,random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "param_grid_stack= {'final_estimator': [RandomForestRegressor(n_estimators=10),\n",
    "                                      RandomForestRegressor(n_estimators=50),\n",
    "                                      RandomForestRegressor(n_estimators=100)]}\n",
    "\n",
    "\n",
    "optimal_params_SVR = GridSearchCV(estimator=reg,\n",
    "                                  param_grid =param_grid_stack,\n",
    "                                  scoring = 'neg_root_mean_squared_error',\n",
    "                                  verbose = 1, n_jobs=-1, cv = 5)\n",
    "\n",
    "optimal_params_SVR.fit(X_train,y_train)\n",
    "optimal_params_SVR.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da832de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('lr', LinearRegression()), ('svr', SVR(C=1)),\n",
       "                              ('xgb',\n",
       "                               XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            enable_categorical=False, gamma=0,\n",
       "                                            gpu_id=-1, importance_type=None,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.1, max_delta_step=0,\n",
       "                                            max_depth=3, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=300, n_jobs=16,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=1,\n",
       "                                            reg_alpha=0, reg_lambda=4,\n",
       "                                            scale_pos_weight=2, subsample=0.5,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None))],\n",
       "                  final_estimator=RandomForestRegressor())"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params_SVR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3804460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_test = LinearRegression()\n",
    "SVR_test = SVR(C=1)\n",
    "xgb_test = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "bag_test = BaggingRegressor(base_estimator=LinearRegression(),n_estimators=250,\n",
    "                             max_samples = 0.25,\n",
    "                             max_features = 0.75,\n",
    "                             bootstrap = False,\n",
    "                             random_state=1,n_jobs=-1)\n",
    "\n",
    "mars_test = \n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('lr', lin_test),\n",
    "    ('svr', SVR_test),\n",
    "    ('xgb',xgb_test),\n",
    "    ('rand',bag_test),\n",
    "    ('mars',mars_test )]\n",
    "\n",
    "\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=50)).fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9b16fab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StackingRegressor' object has no attribute 'feature_importance_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29796/1824877082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importance_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'StackingRegressor' object has no attribute 'feature_importance_'"
     ]
    }
   ],
   "source": [
    "reg.feature_importance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4db0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg.predict(test)\n",
    "preds = np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2463f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.221219985433396"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(preds).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53460bf4",
   "metadata": {},
   "source": [
    "## Preparing and Downloading Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cb6e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_ids.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e20ec05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>6.197751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>5.478291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>4.463193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>5.185648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>5.940109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id         y\n",
       "0  5380  6.197751\n",
       "1  5381  5.478291\n",
       "2  5382  4.463193\n",
       "3  5383  5.185648\n",
       "4  5384  5.940109"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = {'id':test_ids,'y':preds}\n",
    "test_preds = pd.DataFrame(test_preds)\n",
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3cd7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.to_csv('StackHalfLogV1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969e383",
   "metadata": {},
   "source": [
    "## Basic Model Testing\n",
    "\n",
    "#### Note to self: do feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2163d2c",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c73b4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.7538770453292237"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prev got -11.026756557150696 as best\n",
    "param_grid = {'max_depth': [2,3,4],\n",
    "    'learning_rate': [0.05,0.1,0.5],\n",
    "    'reg_lambda':[4,6,8],\n",
    "    'n_estimators':[300,400,500,700,1000],\n",
    "    'gamma':[0,1],\n",
    "    'scale_pos_weight':[1.5,2,3,4],\n",
    "    'subsample':[0.25,0.5,0.75]}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "optimal_params = RandomizedSearchCV(estimator=xgb.XGBRegressor(random_state = 1),\n",
    "                                    n_iter = 25,\n",
    "                                    param_distributions =param_grid,\n",
    "                                    scoring = 'neg_root_mean_squared_error',\n",
    "                                    verbose = 2,n_jobs=-1,cv=5)\n",
    "\n",
    "optimal_params.fit(X_train,y_train)\n",
    "optimal_params.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01eeb592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=1, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=700, n_jobs=16,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
       "             reg_lambda=8, scale_pos_weight=4, subsample=0.5,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e91f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one isn't as good \n",
    "uhhh = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e82ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one got 9.053\n",
    "uhhh = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae06f5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.342965533983604"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = uhhh.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0b04b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca3a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.987268357354584"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parveen is running it\n",
    "rf_test = RandomForestRegressor(max_depth = 15, max_features = 16,min_samples_leaf=5,min_samples_split=3).fit(X_train,y_train)\n",
    "preds = rf_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913889e",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c519ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.500492126282392"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_test = LinearRegression().fit(X_train,y_train)\n",
    "preds = lin_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af48916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.145210494875945"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing after removing the log transformations:\n",
    "lin_test = LinearRegression().fit(X_train,y_train)\n",
    "preds = lin_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb875a3a",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "405f69fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.7423173202963377"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_SVR = {'C': [0.5,0.7,0.25,1]}\n",
    "\n",
    "\n",
    "optimal_params_SVR = GridSearchCV(estimator=SVR(),\n",
    "                                  param_grid =param_grid_SVR,\n",
    "                                  scoring = 'neg_root_mean_squared_error',\n",
    "                                  verbose = 1, n_jobs=-1, cv = 5)\n",
    "\n",
    "optimal_params_SVR.fit(X_train,y_train)\n",
    "optimal_params_SVR.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abd12c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params_SVR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c0007ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.381638663451474"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR_test = SVR(C=1).fit(X_train,y_train)\n",
    "preds = SVR_test.predict(X_test)\n",
    "np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad708aa",
   "metadata": {},
   "source": [
    "### MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21a7bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mars_test = Earth(max_terms = 300, max_degree = 1).fit(X_train,y_train)\n",
    "#preds = mars_test.predict(X_test)\n",
    "#np.sqrt(mean_squared_error(np.exp(preds),np.exp(y_test)))\n",
    "#has been running for like 5 mins as of 11:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgpreds = xgmodel.predict(reduced)\n",
    "param_grid1 = {'max_terms': [400,500,600,800],\n",
    "              'max_degree':[2,3,4,5,6]}\n",
    "#want to optimize on top of the xgboost model\n",
    "optimal_params1 = GridSearchCV(estimator=Earth(),\n",
    "                              param_grid =param_grid1,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 1,n_jobs=-1,cv = 5)\n",
    "optimal_params1.fit(reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c23a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296bb388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e9d93f",
   "metadata": {},
   "source": [
    "### Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_test = LinearRegression()\n",
    "SVR_test = SVR(C=1)\n",
    "xgb_test = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, \n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=16,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
    "             reg_lambda=4, scale_pos_weight=2, subsample=0.5,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "estimators = [\n",
    "    ('lr', lin_test),\n",
    "    ('svr', SVR_test),\n",
    "    ('xgb',xgb_test)]\n",
    "\n",
    "\n",
    "\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators\n",
    "    #final_estimator=RandomForestRegressor(n_estimators=10,random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "param_grid_stack= {'final_estimator': [RandomForestRegressor(n_estimators=10),\n",
    "                                      RandomForestRegressor(n_estimators=50),\n",
    "                                      RandomForestRegressor(n_estimators=100)]}\n",
    "\n",
    "\n",
    "optimal_params_SVR = GridSearchCV(estimator=reg,\n",
    "                                  param_grid =param_grid_stack,\n",
    "                                  scoring = 'neg_root_mean_squared_error',\n",
    "                                  verbose = 1, n_jobs=-1, cv = 5)\n",
    "\n",
    "optimal_params_SVR.fit(X_train,y_train)\n",
    "optimal_params_SVR.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e74e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dc7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bea5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e1e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c64e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd79925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c47f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdeef29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f033a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222a18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76049fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ad054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a71c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887ad73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08179a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc2d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f78051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f901d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3dbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf9c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8aa401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25d066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f4987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc6302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75418672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdcdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e5280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6c221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498a01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28a8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4a2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5e96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3511f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908c886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff6d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93591a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edbbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d3a5e8",
   "metadata": {},
   "source": [
    "#### Basic Data Cleaning (Filling Missing Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a06d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum().max()\n",
    "#LOTS OF NA VALUES, USE UNSUPERVISED LEARNING TO FILL THEM!!!!! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7e1181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (5380, 767)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 120.24\n",
      "[IterativeImputer] Change: 8.029389904441065e+36, scaled tolerance: 5.5683711465182e+38 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman',random_state=0)\n",
    "filled_train=imp.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0625f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>0.706143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id          x001      x002  x003     x004          x005  x006  \\\n",
       "0  0.0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1  1.0  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2  2.0  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3  3.0  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4  4.0  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "\n",
       "          x007       x008       x009  ...    x757          x758  x759   x760  \\\n",
       "0    266117.20   934577.0    14539.0  ...  0.0007  2.972810e+08  0.13    5.0   \n",
       "1  11927742.92  1798051.0  1051272.0  ...  0.1136  3.320000e+12  0.08  661.0   \n",
       "2    774385.01   375738.0   144143.0  ...  0.0029  1.004748e+08  0.39   39.0   \n",
       "3   6324375.16  1932094.0    10055.0  ...  0.0000  3.480000e+11  0.25    2.0   \n",
       "4    169860.29   474253.0    17914.0  ...  0.0005  1.095466e+08  0.11   11.0   \n",
       "\n",
       "   x761   x762     x763    x764      x765     y  \n",
       "0   5.0    2.0   8.5127   14.28 -0.750000   5.0  \n",
       "1   0.0  350.0   1.5700  160.12  0.706143   1.0  \n",
       "2   2.0   18.0   9.6800   25.06 -0.490000  11.0  \n",
       "3   1.0    0.0   4.5316  117.76  1.640000   1.0  \n",
       "4   1.0    3.0  16.2717    5.81 -0.420000   5.0  \n",
       "\n",
       "[5 rows x 767 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_train=pd.DataFrame(filled_train).set_axis(list(train.columns),axis=1)\n",
    "filled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69040384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_train.isna().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac71c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd97ce49",
   "metadata": {},
   "source": [
    "### Import imputed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad41f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_train = pd.read_csv('imputed_data.csv').drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d93030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>0.706143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id          x001      x002  x003     x004          x005  x006  \\\n",
       "0  0.0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1  1.0  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2  2.0  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3  3.0  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4  4.0  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "\n",
       "          x007       x008       x009  ...    x757          x758  x759   x760  \\\n",
       "0    266117.20   934577.0    14539.0  ...  0.0007  2.972810e+08  0.13    5.0   \n",
       "1  11927742.92  1798051.0  1051272.0  ...  0.1136  3.320000e+12  0.08  661.0   \n",
       "2    774385.01   375738.0   144143.0  ...  0.0029  1.004748e+08  0.39   39.0   \n",
       "3   6324375.16  1932094.0    10055.0  ...  0.0000  3.480000e+11  0.25    2.0   \n",
       "4    169860.29   474253.0    17914.0  ...  0.0005  1.095466e+08  0.11   11.0   \n",
       "\n",
       "   x761   x762     x763    x764      x765     y  \n",
       "0   5.0    2.0   8.5127   14.28 -0.750000   5.0  \n",
       "1   0.0  350.0   1.5700  160.12  0.706143   1.0  \n",
       "2   2.0   18.0   9.6800   25.06 -0.490000  11.0  \n",
       "3   1.0    0.0   4.5316  117.76  1.640000   1.0  \n",
       "4   1.0    3.0  16.2717    5.81 -0.420000   5.0  \n",
       "\n",
       "[5 rows x 767 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47281f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3deaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbef1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd2ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cd66e4b",
   "metadata": {},
   "source": [
    "#### Filling with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7e7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "filled_train = KNNImputer(n_neighbors=7).fit_transform(train)\n",
    "filled_train = pd.DataFrame(filled_train)\n",
    "filled_train.columns = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ac6a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 767)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7cb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb42223",
   "metadata": {},
   "source": [
    "### Categorical to dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_train.value_counts().sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd510268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ca801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2920545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d270c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c5401e",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53045135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>2.690000e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5707</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>1.690000e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>4.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>1.350000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>3.700000e+16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>6.000000e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 765 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x001      x002  x003     x004          x005  x006         x007  \\\n",
       "0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31    266117.20   \n",
       "1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00  11927742.92   \n",
       "2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00    774385.01   \n",
       "3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   6324375.16   \n",
       "4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21    169860.29   \n",
       "\n",
       "        x008       x009          x010  ...    x756    x757          x758  \\\n",
       "0   934577.0    14539.0  2.690000e+13  ...  1.5707  0.0007  2.972810e+08   \n",
       "1  1798051.0  1051272.0  1.690000e+17  ...  0.1173  0.1136  3.320000e+12   \n",
       "2   375738.0   144143.0  1.350000e+14  ...  0.4582  0.0029  1.004748e+08   \n",
       "3  1932094.0    10055.0  3.700000e+16  ...  0.3816  0.0000  3.480000e+11   \n",
       "4   474253.0    17914.0  6.000000e+12  ...  0.0100  0.0005  1.095466e+08   \n",
       "\n",
       "   x759   x760  x761   x762     x763    x764      x765  \n",
       "0  0.13    5.0   5.0    2.0   8.5127   14.28 -0.750000  \n",
       "1  0.08  661.0   0.0  350.0   1.5700  160.12  4.814286  \n",
       "2  0.39   39.0   2.0   18.0   9.6800   25.06 -0.490000  \n",
       "3  0.25    2.0   1.0    0.0   4.5316  117.76  1.640000  \n",
       "4  0.11   11.0   1.0    3.0  16.2717    5.81 -0.420000  \n",
       "\n",
       "[5 rows x 765 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = filled_train.drop(columns = ['y','id'])\n",
    "y = filled_train['y']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c9149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5.0\n",
       "1     1.0\n",
       "2    11.0\n",
       "3     1.0\n",
       "4     5.0\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ccc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b1ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c70cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91825a73",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20b4d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2717c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6042d4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.681731</td>\n",
       "      <td>-4.212868</td>\n",
       "      <td>5.627996</td>\n",
       "      <td>-1.498323</td>\n",
       "      <td>-0.219005</td>\n",
       "      <td>2.165506</td>\n",
       "      <td>1.936249</td>\n",
       "      <td>2.984636</td>\n",
       "      <td>-0.449618</td>\n",
       "      <td>-5.104275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273753</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>0.341944</td>\n",
       "      <td>-0.042929</td>\n",
       "      <td>-0.075565</td>\n",
       "      <td>-0.400781</td>\n",
       "      <td>0.092729</td>\n",
       "      <td>-0.186689</td>\n",
       "      <td>0.364549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.995596</td>\n",
       "      <td>7.641858</td>\n",
       "      <td>-6.450976</td>\n",
       "      <td>-5.710635</td>\n",
       "      <td>-3.568207</td>\n",
       "      <td>-3.786723</td>\n",
       "      <td>0.585224</td>\n",
       "      <td>-1.797483</td>\n",
       "      <td>-4.503884</td>\n",
       "      <td>1.292560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238924</td>\n",
       "      <td>-0.393613</td>\n",
       "      <td>-0.037135</td>\n",
       "      <td>0.403295</td>\n",
       "      <td>0.141959</td>\n",
       "      <td>0.507092</td>\n",
       "      <td>-0.294299</td>\n",
       "      <td>-0.324151</td>\n",
       "      <td>-0.409748</td>\n",
       "      <td>0.058943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.087225</td>\n",
       "      <td>-7.580140</td>\n",
       "      <td>5.437322</td>\n",
       "      <td>-3.054125</td>\n",
       "      <td>0.611241</td>\n",
       "      <td>1.188735</td>\n",
       "      <td>2.292602</td>\n",
       "      <td>2.338374</td>\n",
       "      <td>-0.065795</td>\n",
       "      <td>-5.173503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079198</td>\n",
       "      <td>-0.383796</td>\n",
       "      <td>0.302809</td>\n",
       "      <td>0.238745</td>\n",
       "      <td>0.076195</td>\n",
       "      <td>-0.132216</td>\n",
       "      <td>-0.173578</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.172780</td>\n",
       "      <td>-0.229469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-14.186316</td>\n",
       "      <td>0.186148</td>\n",
       "      <td>-5.996532</td>\n",
       "      <td>-2.840320</td>\n",
       "      <td>-7.040556</td>\n",
       "      <td>-0.597031</td>\n",
       "      <td>0.487076</td>\n",
       "      <td>4.129280</td>\n",
       "      <td>0.287605</td>\n",
       "      <td>-1.112313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142687</td>\n",
       "      <td>-0.218435</td>\n",
       "      <td>-0.254740</td>\n",
       "      <td>-0.321936</td>\n",
       "      <td>-0.346965</td>\n",
       "      <td>-0.582441</td>\n",
       "      <td>-0.236476</td>\n",
       "      <td>0.397019</td>\n",
       "      <td>-0.522466</td>\n",
       "      <td>0.288247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.956584</td>\n",
       "      <td>-0.304867</td>\n",
       "      <td>1.491399</td>\n",
       "      <td>-4.916673</td>\n",
       "      <td>3.510620</td>\n",
       "      <td>0.492855</td>\n",
       "      <td>2.031994</td>\n",
       "      <td>3.622570</td>\n",
       "      <td>-4.879888</td>\n",
       "      <td>-2.209249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151175</td>\n",
       "      <td>-0.219023</td>\n",
       "      <td>0.290319</td>\n",
       "      <td>-0.242131</td>\n",
       "      <td>-0.160081</td>\n",
       "      <td>-0.167740</td>\n",
       "      <td>-0.103394</td>\n",
       "      <td>0.266801</td>\n",
       "      <td>0.079869</td>\n",
       "      <td>0.400560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   3.681731 -4.212868  5.627996 -1.498323 -0.219005  2.165506  1.936249   \n",
       "1 -16.995596  7.641858 -6.450976 -5.710635 -3.568207 -3.786723  0.585224   \n",
       "2  -3.087225 -7.580140  5.437322 -3.054125  0.611241  1.188735  2.292602   \n",
       "3 -14.186316  0.186148 -5.996532 -2.840320 -7.040556 -0.597031  0.487076   \n",
       "4  -0.956584 -0.304867  1.491399 -4.916673  3.510620  0.492855  2.031994   \n",
       "\n",
       "        7         8         9    ...       211       212       213       214  \\\n",
       "0  2.984636 -0.449618 -5.104275  ... -0.273753  0.012153  0.020311  0.341944   \n",
       "1 -1.797483 -4.503884  1.292560  ... -0.238924 -0.393613 -0.037135  0.403295   \n",
       "2  2.338374 -0.065795 -5.173503  ... -0.079198 -0.383796  0.302809  0.238745   \n",
       "3  4.129280  0.287605 -1.112313  ...  0.142687 -0.218435 -0.254740 -0.321936   \n",
       "4  3.622570 -4.879888 -2.209249  ... -0.151175 -0.219023  0.290319 -0.242131   \n",
       "\n",
       "        215       216       217       218       219       220  \n",
       "0 -0.042929 -0.075565 -0.400781  0.092729 -0.186689  0.364549  \n",
       "1  0.141959  0.507092 -0.294299 -0.324151 -0.409748  0.058943  \n",
       "2  0.076195 -0.132216 -0.173578  0.112998  0.172780 -0.229469  \n",
       "3 -0.346965 -0.582441 -0.236476  0.397019 -0.522466  0.288247  \n",
       "4 -0.160081 -0.167740 -0.103394  0.266801  0.079869  0.400560  \n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99)\n",
    "pca.fit(X_train_scaled)\n",
    "reduced = pd.DataFrame(pca.transform(X_train_scaled))\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b6e92337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>0.706143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5375.0</td>\n",
       "      <td>3.948791e+09</td>\n",
       "      <td>24563.46</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>9.871977e+08</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3303184.55</td>\n",
       "      <td>3154159.0</td>\n",
       "      <td>4439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.586033e+08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7480</td>\n",
       "      <td>93.45</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>5376.0</td>\n",
       "      <td>9.279017e+10</td>\n",
       "      <td>21572.94</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>3.093006e+09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2649164.57</td>\n",
       "      <td>2934417.0</td>\n",
       "      <td>19106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>3.608917e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.6890</td>\n",
       "      <td>76.05</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>5377.0</td>\n",
       "      <td>2.700359e+10</td>\n",
       "      <td>23061.73</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>3.857656e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1825306.07</td>\n",
       "      <td>2395841.0</td>\n",
       "      <td>71514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>1.786891e+06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.3710</td>\n",
       "      <td>80.30</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>5378.0</td>\n",
       "      <td>4.351107e+10</td>\n",
       "      <td>5739.04</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.318517e+09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>144103.12</td>\n",
       "      <td>715173.0</td>\n",
       "      <td>13977.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.940000e+11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.6594</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>5379.0</td>\n",
       "      <td>3.972951e+09</td>\n",
       "      <td>3368.55</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.324317e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>471263.24</td>\n",
       "      <td>419675.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.740000e+12</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0195</td>\n",
       "      <td>19.07</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          x001      x002  x003     x004          x005  x006  \\\n",
       "0        0.0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1        1.0  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2        2.0  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3        3.0  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4        4.0  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "...      ...           ...       ...   ...      ...           ...   ...   \n",
       "5375  5375.0  3.948791e+09  24563.46  6.73  0.00035  9.871977e+08  0.43   \n",
       "5376  5376.0  9.279017e+10  21572.94  6.96  0.00120  3.093006e+09  0.30   \n",
       "5377  5377.0  2.700359e+10  23061.73  6.36  0.00065  3.857656e+09  0.35   \n",
       "5378  5378.0  4.351107e+10   5739.04  7.80  0.00065  1.318517e+09  0.29   \n",
       "5379  5379.0  3.972951e+09   3368.55  6.15  0.00000  1.324317e+09  0.00   \n",
       "\n",
       "             x007       x008       x009  ...    x757          x758  x759  \\\n",
       "0       266117.20   934577.0    14539.0  ...  0.0007  2.972810e+08  0.13   \n",
       "1     11927742.92  1798051.0  1051272.0  ...  0.1136  3.320000e+12  0.08   \n",
       "2       774385.01   375738.0   144143.0  ...  0.0029  1.004748e+08  0.39   \n",
       "3      6324375.16  1932094.0    10055.0  ...  0.0000  3.480000e+11  0.25   \n",
       "4       169860.29   474253.0    17914.0  ...  0.0005  1.095466e+08  0.11   \n",
       "...           ...        ...        ...  ...     ...           ...   ...   \n",
       "5375   3303184.55  3154159.0     4439.0  ...  0.0000  1.586033e+08  0.05   \n",
       "5376   2649164.57  2934417.0    19106.0  ...  0.0003  3.608917e+07  0.01   \n",
       "5377   1825306.07  2395841.0    71514.0  ...  0.0057  1.786891e+06  0.53   \n",
       "5378    144103.12   715173.0    13977.0  ...  0.0001  1.940000e+11  0.29   \n",
       "5379    471263.24   419675.0     1457.0  ...  0.0000  5.740000e+12  0.51   \n",
       "\n",
       "       x760  x761   x762     x763    x764      x765     y  \n",
       "0       5.0   5.0    2.0   8.5127   14.28 -0.750000   5.0  \n",
       "1     661.0   0.0  350.0   1.5700  160.12  0.706143   1.0  \n",
       "2      39.0   2.0   18.0   9.6800   25.06 -0.490000  11.0  \n",
       "3       2.0   1.0    0.0   4.5316  117.76  1.640000   1.0  \n",
       "4      11.0   1.0    3.0  16.2717    5.81 -0.420000   5.0  \n",
       "...     ...   ...    ...      ...     ...       ...   ...  \n",
       "5375    0.0   0.0    0.0   2.7480   93.45  0.220000   4.0  \n",
       "5376    6.0   4.0    4.0  23.6890   76.05 -0.900000   8.0  \n",
       "5377   44.0   0.0   28.0   4.3710   80.30 -0.700000  21.0  \n",
       "5378    3.0   2.0    2.0  24.6594    7.95  0.470000  13.0  \n",
       "5379    0.0   0.0    0.0   2.0195   19.07  0.190000  28.0  \n",
       "\n",
       "[5380 rows x 767 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec77e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff2181e",
   "metadata": {},
   "source": [
    "# TRAIN TEST PREPARATION FOR GOOGLE CLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7e2cd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.588199</td>\n",
       "      <td>3.539501</td>\n",
       "      <td>-0.032585</td>\n",
       "      <td>-5.492283</td>\n",
       "      <td>0.732118</td>\n",
       "      <td>1.038576</td>\n",
       "      <td>-0.983127</td>\n",
       "      <td>1.605731</td>\n",
       "      <td>-1.038706</td>\n",
       "      <td>-0.755261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495472</td>\n",
       "      <td>-0.697193</td>\n",
       "      <td>-0.177941</td>\n",
       "      <td>0.076079</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>-0.002279</td>\n",
       "      <td>-0.596124</td>\n",
       "      <td>0.189532</td>\n",
       "      <td>-0.285545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963662</td>\n",
       "      <td>-13.285920</td>\n",
       "      <td>0.342913</td>\n",
       "      <td>-8.175269</td>\n",
       "      <td>-0.359248</td>\n",
       "      <td>1.292364</td>\n",
       "      <td>2.068324</td>\n",
       "      <td>-5.501549</td>\n",
       "      <td>1.400887</td>\n",
       "      <td>3.715703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289510</td>\n",
       "      <td>0.457298</td>\n",
       "      <td>-0.067202</td>\n",
       "      <td>-0.266022</td>\n",
       "      <td>0.379997</td>\n",
       "      <td>-0.214967</td>\n",
       "      <td>-0.121989</td>\n",
       "      <td>0.133325</td>\n",
       "      <td>0.166580</td>\n",
       "      <td>0.432410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.580953</td>\n",
       "      <td>-6.833888</td>\n",
       "      <td>0.292097</td>\n",
       "      <td>-4.199219</td>\n",
       "      <td>3.667237</td>\n",
       "      <td>-1.034527</td>\n",
       "      <td>-1.798313</td>\n",
       "      <td>-2.908432</td>\n",
       "      <td>1.015553</td>\n",
       "      <td>5.796897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110436</td>\n",
       "      <td>-0.449203</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.265526</td>\n",
       "      <td>0.141199</td>\n",
       "      <td>0.131686</td>\n",
       "      <td>-0.416616</td>\n",
       "      <td>-0.013384</td>\n",
       "      <td>0.152158</td>\n",
       "      <td>-0.479467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.718006</td>\n",
       "      <td>-8.544124</td>\n",
       "      <td>0.682982</td>\n",
       "      <td>5.481525</td>\n",
       "      <td>8.287062</td>\n",
       "      <td>-3.617004</td>\n",
       "      <td>2.229315</td>\n",
       "      <td>-5.030848</td>\n",
       "      <td>-0.604742</td>\n",
       "      <td>-2.398265</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103567</td>\n",
       "      <td>1.015632</td>\n",
       "      <td>0.688472</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>-0.883302</td>\n",
       "      <td>-0.383907</td>\n",
       "      <td>-0.154535</td>\n",
       "      <td>-0.288710</td>\n",
       "      <td>0.064097</td>\n",
       "      <td>-0.049317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.962767</td>\n",
       "      <td>0.229033</td>\n",
       "      <td>-1.437204</td>\n",
       "      <td>5.206142</td>\n",
       "      <td>-13.648702</td>\n",
       "      <td>-0.048442</td>\n",
       "      <td>10.299157</td>\n",
       "      <td>-2.965839</td>\n",
       "      <td>3.306514</td>\n",
       "      <td>-5.901674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653706</td>\n",
       "      <td>-0.038858</td>\n",
       "      <td>-0.107797</td>\n",
       "      <td>0.692134</td>\n",
       "      <td>0.346191</td>\n",
       "      <td>0.189712</td>\n",
       "      <td>-0.136785</td>\n",
       "      <td>-0.472035</td>\n",
       "      <td>0.204340</td>\n",
       "      <td>0.092310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1         2         3          4         5          6    \\\n",
       "0  14.588199   3.539501 -0.032585 -5.492283   0.732118  1.038576  -0.983127   \n",
       "1   0.963662 -13.285920  0.342913 -8.175269  -0.359248  1.292364   2.068324   \n",
       "2   6.580953  -6.833888  0.292097 -4.199219   3.667237 -1.034527  -1.798313   \n",
       "3   7.718006  -8.544124  0.682982  5.481525   8.287062 -3.617004   2.229315   \n",
       "4 -11.962767   0.229033 -1.437204  5.206142 -13.648702 -0.048442  10.299157   \n",
       "\n",
       "        7         8         9    ...       215       216       217       218  \\\n",
       "0  1.605731 -1.038706 -0.755261  ... -0.495472 -0.697193 -0.177941  0.076079   \n",
       "1 -5.501549  1.400887  3.715703  ...  0.289510  0.457298 -0.067202 -0.266022   \n",
       "2 -2.908432  1.015553  5.796897  ...  0.110436 -0.449203 -0.083471 -0.265526   \n",
       "3 -5.030848 -0.604742 -2.398265  ...  1.103567  1.015632  0.688472  0.114000   \n",
       "4 -2.965839  3.306514 -5.901674  ...  0.653706 -0.038858 -0.107797  0.692134   \n",
       "\n",
       "        219       220       221       222       223       224  \n",
       "0  0.095141  0.050001 -0.002279 -0.596124  0.189532 -0.285545  \n",
       "1  0.379997 -0.214967 -0.121989  0.133325  0.166580  0.432410  \n",
       "2  0.141199  0.131686 -0.416616 -0.013384  0.152158 -0.479467  \n",
       "3 -0.883302 -0.383907 -0.154535 -0.288710  0.064097 -0.049317  \n",
       "4  0.346191  0.189712 -0.136785 -0.472035  0.204340  0.092310  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "filled_train = KNNImputer(n_neighbors=7).fit_transform(train)\n",
    "filled_train = pd.DataFrame(filled_train)\n",
    "filled_train.columns = train.columns\n",
    "\n",
    "X = filled_train.drop(columns = ['y','id'])\n",
    "y = filled_train['y']\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "\n",
    "X_scaled = sc.transform(X)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "pca.fit(X_scaled)\n",
    "reduced = pd.DataFrame(pca.transform(X_scaled))\n",
    "\n",
    "reduced['y'] = y\n",
    "\n",
    "\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "filled_test = KNNImputer(n_neighbors =7).fit_transform(test)\n",
    "filled_test = pd.DataFrame(filled_test)\n",
    "filled_test.columns = test.columns\n",
    "\n",
    "filled_test_no_id = filled_test.drop(columns = 'id')\n",
    "\n",
    "filled_test_no_id_scaled = pd.DataFrame(sc.transform(filled_test_no_id))\n",
    "\n",
    "reduced_test = pd.DataFrame(pca.transform(filled_test_no_id_scaled))\n",
    "\n",
    "\n",
    "reduced_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8fa9116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.777733</td>\n",
       "      <td>-10.520174</td>\n",
       "      <td>-1.537274</td>\n",
       "      <td>11.392587</td>\n",
       "      <td>-3.634160</td>\n",
       "      <td>0.199428</td>\n",
       "      <td>2.034389</td>\n",
       "      <td>-3.979034</td>\n",
       "      <td>1.113452</td>\n",
       "      <td>-0.240106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204847</td>\n",
       "      <td>-0.236157</td>\n",
       "      <td>0.405733</td>\n",
       "      <td>-0.203683</td>\n",
       "      <td>-0.292291</td>\n",
       "      <td>0.680371</td>\n",
       "      <td>-0.226556</td>\n",
       "      <td>-0.036468</td>\n",
       "      <td>-0.090554</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.944003</td>\n",
       "      <td>0.620033</td>\n",
       "      <td>1.665361</td>\n",
       "      <td>-2.860618</td>\n",
       "      <td>5.398140</td>\n",
       "      <td>7.948242</td>\n",
       "      <td>0.928259</td>\n",
       "      <td>-2.337363</td>\n",
       "      <td>-1.135414</td>\n",
       "      <td>-2.615501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173530</td>\n",
       "      <td>-0.014092</td>\n",
       "      <td>1.095678</td>\n",
       "      <td>-0.291133</td>\n",
       "      <td>0.242876</td>\n",
       "      <td>-0.772537</td>\n",
       "      <td>-0.066390</td>\n",
       "      <td>-0.246352</td>\n",
       "      <td>-0.647632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.450869</td>\n",
       "      <td>-9.229399</td>\n",
       "      <td>1.835411</td>\n",
       "      <td>-2.966956</td>\n",
       "      <td>0.630919</td>\n",
       "      <td>2.935805</td>\n",
       "      <td>-2.030275</td>\n",
       "      <td>4.810756</td>\n",
       "      <td>-1.938653</td>\n",
       "      <td>-2.236510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084425</td>\n",
       "      <td>0.025172</td>\n",
       "      <td>-0.473026</td>\n",
       "      <td>0.125705</td>\n",
       "      <td>-0.146965</td>\n",
       "      <td>0.121982</td>\n",
       "      <td>0.030862</td>\n",
       "      <td>0.184824</td>\n",
       "      <td>-0.156294</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.300515</td>\n",
       "      <td>-4.508703</td>\n",
       "      <td>4.375889</td>\n",
       "      <td>-3.278292</td>\n",
       "      <td>-1.106832</td>\n",
       "      <td>-0.296198</td>\n",
       "      <td>2.795106</td>\n",
       "      <td>0.256905</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>-2.932013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>-0.338448</td>\n",
       "      <td>0.384057</td>\n",
       "      <td>-0.279003</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>-0.044272</td>\n",
       "      <td>-0.670641</td>\n",
       "      <td>-0.174885</td>\n",
       "      <td>0.246227</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.383652</td>\n",
       "      <td>-4.841427</td>\n",
       "      <td>-0.560100</td>\n",
       "      <td>-5.808735</td>\n",
       "      <td>4.557986</td>\n",
       "      <td>0.396965</td>\n",
       "      <td>-3.088530</td>\n",
       "      <td>2.326427</td>\n",
       "      <td>-8.318162</td>\n",
       "      <td>3.265056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639403</td>\n",
       "      <td>-0.298415</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.343766</td>\n",
       "      <td>-0.107785</td>\n",
       "      <td>-0.205230</td>\n",
       "      <td>-0.084525</td>\n",
       "      <td>-0.380670</td>\n",
       "      <td>0.370388</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4         5         6  \\\n",
       "0  10.777733 -10.520174 -1.537274  11.392587 -3.634160  0.199428  2.034389   \n",
       "1 -13.944003   0.620033  1.665361  -2.860618  5.398140  7.948242  0.928259   \n",
       "2   3.450869  -9.229399  1.835411  -2.966956  0.630919  2.935805 -2.030275   \n",
       "3  -4.300515  -4.508703  4.375889  -3.278292 -1.106832 -0.296198  2.795106   \n",
       "4   8.383652  -4.841427 -0.560100  -5.808735  4.557986  0.396965 -3.088530   \n",
       "\n",
       "          7         8         9  ...       216       217       218       219  \\\n",
       "0 -3.979034  1.113452 -0.240106  ...  0.204847 -0.236157  0.405733 -0.203683   \n",
       "1 -2.337363 -1.135414 -2.615501  ...  0.173530 -0.014092  1.095678 -0.291133   \n",
       "2  4.810756 -1.938653 -2.236510  ... -0.084425  0.025172 -0.473026  0.125705   \n",
       "3  0.256905  0.873391 -2.932013  ...  0.034527 -0.338448  0.384057 -0.279003   \n",
       "4  2.326427 -8.318162  3.265056  ...  0.639403 -0.298415  0.042641  0.343766   \n",
       "\n",
       "        220       221       222       223       224     y  \n",
       "0 -0.292291  0.680371 -0.226556 -0.036468 -0.090554   5.0  \n",
       "1  0.242876 -0.772537 -0.066390 -0.246352 -0.647632   1.0  \n",
       "2 -0.146965  0.121982  0.030862  0.184824 -0.156294  11.0  \n",
       "3  0.087071 -0.044272 -0.670641 -0.174885  0.246227   1.0  \n",
       "4 -0.107785 -0.205230 -0.084525 -0.380670  0.370388   5.0  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa856f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.777733</td>\n",
       "      <td>-10.520174</td>\n",
       "      <td>-1.537274</td>\n",
       "      <td>11.392587</td>\n",
       "      <td>-3.634160</td>\n",
       "      <td>0.199428</td>\n",
       "      <td>2.034389</td>\n",
       "      <td>-3.979034</td>\n",
       "      <td>1.113452</td>\n",
       "      <td>-0.240106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204847</td>\n",
       "      <td>-0.236157</td>\n",
       "      <td>0.405733</td>\n",
       "      <td>-0.203683</td>\n",
       "      <td>-0.292291</td>\n",
       "      <td>0.680371</td>\n",
       "      <td>-0.226556</td>\n",
       "      <td>-0.036468</td>\n",
       "      <td>-0.090554</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.944003</td>\n",
       "      <td>0.620033</td>\n",
       "      <td>1.665361</td>\n",
       "      <td>-2.860618</td>\n",
       "      <td>5.398140</td>\n",
       "      <td>7.948242</td>\n",
       "      <td>0.928259</td>\n",
       "      <td>-2.337363</td>\n",
       "      <td>-1.135414</td>\n",
       "      <td>-2.615501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173530</td>\n",
       "      <td>-0.014092</td>\n",
       "      <td>1.095678</td>\n",
       "      <td>-0.291133</td>\n",
       "      <td>0.242876</td>\n",
       "      <td>-0.772537</td>\n",
       "      <td>-0.066390</td>\n",
       "      <td>-0.246352</td>\n",
       "      <td>-0.647632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.450869</td>\n",
       "      <td>-9.229399</td>\n",
       "      <td>1.835411</td>\n",
       "      <td>-2.966956</td>\n",
       "      <td>0.630919</td>\n",
       "      <td>2.935805</td>\n",
       "      <td>-2.030275</td>\n",
       "      <td>4.810756</td>\n",
       "      <td>-1.938653</td>\n",
       "      <td>-2.236510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084425</td>\n",
       "      <td>0.025172</td>\n",
       "      <td>-0.473026</td>\n",
       "      <td>0.125705</td>\n",
       "      <td>-0.146965</td>\n",
       "      <td>0.121982</td>\n",
       "      <td>0.030862</td>\n",
       "      <td>0.184824</td>\n",
       "      <td>-0.156294</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.300515</td>\n",
       "      <td>-4.508703</td>\n",
       "      <td>4.375889</td>\n",
       "      <td>-3.278292</td>\n",
       "      <td>-1.106832</td>\n",
       "      <td>-0.296198</td>\n",
       "      <td>2.795106</td>\n",
       "      <td>0.256905</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>-2.932013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>-0.338448</td>\n",
       "      <td>0.384057</td>\n",
       "      <td>-0.279003</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>-0.044272</td>\n",
       "      <td>-0.670641</td>\n",
       "      <td>-0.174885</td>\n",
       "      <td>0.246227</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.383652</td>\n",
       "      <td>-4.841427</td>\n",
       "      <td>-0.560100</td>\n",
       "      <td>-5.808735</td>\n",
       "      <td>4.557986</td>\n",
       "      <td>0.396965</td>\n",
       "      <td>-3.088530</td>\n",
       "      <td>2.326427</td>\n",
       "      <td>-8.318162</td>\n",
       "      <td>3.265056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639403</td>\n",
       "      <td>-0.298415</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.343766</td>\n",
       "      <td>-0.107785</td>\n",
       "      <td>-0.205230</td>\n",
       "      <td>-0.084525</td>\n",
       "      <td>-0.380670</td>\n",
       "      <td>0.370388</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4         5         6  \\\n",
       "0  10.777733 -10.520174 -1.537274  11.392587 -3.634160  0.199428  2.034389   \n",
       "1 -13.944003   0.620033  1.665361  -2.860618  5.398140  7.948242  0.928259   \n",
       "2   3.450869  -9.229399  1.835411  -2.966956  0.630919  2.935805 -2.030275   \n",
       "3  -4.300515  -4.508703  4.375889  -3.278292 -1.106832 -0.296198  2.795106   \n",
       "4   8.383652  -4.841427 -0.560100  -5.808735  4.557986  0.396965 -3.088530   \n",
       "\n",
       "          7         8         9  ...       216       217       218       219  \\\n",
       "0 -3.979034  1.113452 -0.240106  ...  0.204847 -0.236157  0.405733 -0.203683   \n",
       "1 -2.337363 -1.135414 -2.615501  ...  0.173530 -0.014092  1.095678 -0.291133   \n",
       "2  4.810756 -1.938653 -2.236510  ... -0.084425  0.025172 -0.473026  0.125705   \n",
       "3  0.256905  0.873391 -2.932013  ...  0.034527 -0.338448  0.384057 -0.279003   \n",
       "4  2.326427 -8.318162  3.265056  ...  0.639403 -0.298415  0.042641  0.343766   \n",
       "\n",
       "        220       221       222       223       224     y  \n",
       "0 -0.292291  0.680371 -0.226556 -0.036468 -0.090554   5.0  \n",
       "1  0.242876 -0.772537 -0.066390 -0.246352 -0.647632   1.0  \n",
       "2 -0.146965  0.121982  0.030862  0.184824 -0.156294  11.0  \n",
       "3  0.087071 -0.044272 -0.670641 -0.174885  0.246227   1.0  \n",
       "4 -0.107785 -0.205230 -0.084525 -0.380670  0.370388   5.0  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced['y'] = pd.to_numeric(reduced['y'])\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ccdbebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.to_csv('Prepped Training V2.csv',index = False)\n",
    "reduced_test.to_csv('Prepped Test V2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fcdcd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.777733</td>\n",
       "      <td>-10.520174</td>\n",
       "      <td>-1.537274</td>\n",
       "      <td>11.392587</td>\n",
       "      <td>-3.634160</td>\n",
       "      <td>0.199428</td>\n",
       "      <td>2.034389</td>\n",
       "      <td>-3.979034</td>\n",
       "      <td>1.113452</td>\n",
       "      <td>-0.240106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204847</td>\n",
       "      <td>-0.236157</td>\n",
       "      <td>0.405733</td>\n",
       "      <td>-0.203683</td>\n",
       "      <td>-0.292291</td>\n",
       "      <td>0.680371</td>\n",
       "      <td>-0.226556</td>\n",
       "      <td>-0.036468</td>\n",
       "      <td>-0.090554</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.383652</td>\n",
       "      <td>-4.841427</td>\n",
       "      <td>-0.560100</td>\n",
       "      <td>-5.808735</td>\n",
       "      <td>4.557986</td>\n",
       "      <td>0.396965</td>\n",
       "      <td>-3.088530</td>\n",
       "      <td>2.326427</td>\n",
       "      <td>-8.318162</td>\n",
       "      <td>3.265056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639403</td>\n",
       "      <td>-0.298415</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.343766</td>\n",
       "      <td>-0.107785</td>\n",
       "      <td>-0.205230</td>\n",
       "      <td>-0.084525</td>\n",
       "      <td>-0.380670</td>\n",
       "      <td>0.370388</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-12.892026</td>\n",
       "      <td>0.289710</td>\n",
       "      <td>5.264769</td>\n",
       "      <td>-0.834164</td>\n",
       "      <td>6.825016</td>\n",
       "      <td>24.465080</td>\n",
       "      <td>-8.256306</td>\n",
       "      <td>-15.041935</td>\n",
       "      <td>5.638843</td>\n",
       "      <td>0.819544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126669</td>\n",
       "      <td>-0.591322</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>-0.584554</td>\n",
       "      <td>0.312808</td>\n",
       "      <td>0.111108</td>\n",
       "      <td>0.079825</td>\n",
       "      <td>-0.146563</td>\n",
       "      <td>0.137005</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-6.242144</td>\n",
       "      <td>-5.540674</td>\n",
       "      <td>-0.444804</td>\n",
       "      <td>1.346923</td>\n",
       "      <td>7.165952</td>\n",
       "      <td>-2.759833</td>\n",
       "      <td>3.329869</td>\n",
       "      <td>-3.052719</td>\n",
       "      <td>6.941070</td>\n",
       "      <td>-6.551071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361874</td>\n",
       "      <td>0.220164</td>\n",
       "      <td>-0.097614</td>\n",
       "      <td>-0.126637</td>\n",
       "      <td>0.162782</td>\n",
       "      <td>-0.035048</td>\n",
       "      <td>0.459411</td>\n",
       "      <td>-0.588638</td>\n",
       "      <td>0.016906</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-6.205359</td>\n",
       "      <td>-0.918287</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>-7.017089</td>\n",
       "      <td>-2.922056</td>\n",
       "      <td>-0.600768</td>\n",
       "      <td>-1.979298</td>\n",
       "      <td>0.275233</td>\n",
       "      <td>-1.465363</td>\n",
       "      <td>3.625314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217351</td>\n",
       "      <td>-0.053715</td>\n",
       "      <td>0.052596</td>\n",
       "      <td>-0.104351</td>\n",
       "      <td>-0.024896</td>\n",
       "      <td>0.076155</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.416118</td>\n",
       "      <td>-0.140862</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>0.422032</td>\n",
       "      <td>-4.348784</td>\n",
       "      <td>3.371351</td>\n",
       "      <td>3.315203</td>\n",
       "      <td>12.587683</td>\n",
       "      <td>-4.080978</td>\n",
       "      <td>1.342671</td>\n",
       "      <td>-3.024569</td>\n",
       "      <td>-2.951812</td>\n",
       "      <td>-1.199389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070745</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>-0.655325</td>\n",
       "      <td>0.292150</td>\n",
       "      <td>-0.397970</td>\n",
       "      <td>-0.196182</td>\n",
       "      <td>0.121279</td>\n",
       "      <td>0.073152</td>\n",
       "      <td>-0.144393</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>9.322460</td>\n",
       "      <td>-11.410972</td>\n",
       "      <td>-1.352566</td>\n",
       "      <td>-8.688582</td>\n",
       "      <td>-3.617279</td>\n",
       "      <td>0.800365</td>\n",
       "      <td>-5.578573</td>\n",
       "      <td>-1.618356</td>\n",
       "      <td>3.054094</td>\n",
       "      <td>6.966492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882430</td>\n",
       "      <td>0.314664</td>\n",
       "      <td>-0.295539</td>\n",
       "      <td>1.006019</td>\n",
       "      <td>0.555174</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>-0.092022</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>0.815980</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>-2.920529</td>\n",
       "      <td>-0.873640</td>\n",
       "      <td>-2.715245</td>\n",
       "      <td>3.244687</td>\n",
       "      <td>7.524971</td>\n",
       "      <td>-4.776271</td>\n",
       "      <td>-0.976519</td>\n",
       "      <td>-1.174828</td>\n",
       "      <td>1.844731</td>\n",
       "      <td>0.097640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077732</td>\n",
       "      <td>0.233639</td>\n",
       "      <td>0.152072</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>0.196147</td>\n",
       "      <td>0.447806</td>\n",
       "      <td>-0.098758</td>\n",
       "      <td>-0.056151</td>\n",
       "      <td>0.124438</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>19.270067</td>\n",
       "      <td>3.874647</td>\n",
       "      <td>1.707228</td>\n",
       "      <td>-5.333819</td>\n",
       "      <td>4.407820</td>\n",
       "      <td>1.344145</td>\n",
       "      <td>0.036535</td>\n",
       "      <td>-1.063708</td>\n",
       "      <td>-6.982951</td>\n",
       "      <td>0.681969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.409375</td>\n",
       "      <td>0.257010</td>\n",
       "      <td>-0.482816</td>\n",
       "      <td>-0.099588</td>\n",
       "      <td>-0.096670</td>\n",
       "      <td>-0.246878</td>\n",
       "      <td>0.264177</td>\n",
       "      <td>-0.334742</td>\n",
       "      <td>-0.032604</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>-6.759350</td>\n",
       "      <td>-10.350922</td>\n",
       "      <td>-12.350392</td>\n",
       "      <td>11.257892</td>\n",
       "      <td>-11.490478</td>\n",
       "      <td>1.914904</td>\n",
       "      <td>6.495160</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>-5.376580</td>\n",
       "      <td>0.801085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190106</td>\n",
       "      <td>0.185597</td>\n",
       "      <td>-0.553886</td>\n",
       "      <td>-0.473208</td>\n",
       "      <td>-0.015319</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.073380</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>-0.020736</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "0     10.777733 -10.520174  -1.537274  11.392587  -3.634160   0.199428   \n",
       "4      8.383652  -4.841427  -0.560100  -5.808735   4.557986   0.396965   \n",
       "12   -12.892026   0.289710   5.264769  -0.834164   6.825016  24.465080   \n",
       "21    -6.242144  -5.540674  -0.444804   1.346923   7.165952  -2.759833   \n",
       "25    -6.205359  -0.918287  -1.256234  -7.017089  -2.922056  -0.600768   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "5286   0.422032  -4.348784   3.371351   3.315203  12.587683  -4.080978   \n",
       "5300   9.322460 -11.410972  -1.352566  -8.688582  -3.617279   0.800365   \n",
       "5316  -2.920529  -0.873640  -2.715245   3.244687   7.524971  -4.776271   \n",
       "5343  19.270067   3.874647   1.707228  -5.333819   4.407820   1.344145   \n",
       "5357  -6.759350 -10.350922 -12.350392  11.257892 -11.490478   1.914904   \n",
       "\n",
       "             6          7         8         9  ...       216       217  \\\n",
       "0     2.034389  -3.979034  1.113452 -0.240106  ...  0.204847 -0.236157   \n",
       "4    -3.088530   2.326427 -8.318162  3.265056  ...  0.639403 -0.298415   \n",
       "12   -8.256306 -15.041935  5.638843  0.819544  ...  0.126669 -0.591322   \n",
       "21    3.329869  -3.052719  6.941070 -6.551071  ... -0.361874  0.220164   \n",
       "25   -1.979298   0.275233 -1.465363  3.625314  ...  0.217351 -0.053715   \n",
       "...        ...        ...       ...       ...  ...       ...       ...   \n",
       "5286  1.342671  -3.024569 -2.951812 -1.199389  ...  0.070745 -0.018998   \n",
       "5300 -5.578573  -1.618356  3.054094  6.966492  ...  0.882430  0.314664   \n",
       "5316 -0.976519  -1.174828  1.844731  0.097640  ...  0.077732  0.233639   \n",
       "5343  0.036535  -1.063708 -6.982951  0.681969  ... -0.409375  0.257010   \n",
       "5357  6.495160   0.767742 -5.376580  0.801085  ... -0.190106  0.185597   \n",
       "\n",
       "           218       219       220       221       222       223       224  \\\n",
       "0     0.405733 -0.203683 -0.292291  0.680371 -0.226556 -0.036468 -0.090554   \n",
       "4     0.042641  0.343766 -0.107785 -0.205230 -0.084525 -0.380670  0.370388   \n",
       "12    0.185100 -0.584554  0.312808  0.111108  0.079825 -0.146563  0.137005   \n",
       "21   -0.097614 -0.126637  0.162782 -0.035048  0.459411 -0.588638  0.016906   \n",
       "25    0.052596 -0.104351 -0.024896  0.076155  0.114631  0.416118 -0.140862   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5286 -0.655325  0.292150 -0.397970 -0.196182  0.121279  0.073152 -0.144393   \n",
       "5300 -0.295539  1.006019  0.555174  0.108135 -0.092022  0.780687  0.815980   \n",
       "5316  0.152072  0.291712  0.196147  0.447806 -0.098758 -0.056151  0.124438   \n",
       "5343 -0.482816 -0.099588 -0.096670 -0.246878  0.264177 -0.334742 -0.032604   \n",
       "5357 -0.553886 -0.473208 -0.015319  0.032038  0.073380  0.018581 -0.020736   \n",
       "\n",
       "        y  \n",
       "0     5.0  \n",
       "4     5.0  \n",
       "12    5.0  \n",
       "21    5.0  \n",
       "25    5.0  \n",
       "...   ...  \n",
       "5286  5.0  \n",
       "5300  5.0  \n",
       "5316  5.0  \n",
       "5343  5.0  \n",
       "5357  5.0  \n",
       "\n",
       "[390 rows x 226 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced[reduced['y'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "857a13e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7800"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fadc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac94e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d559c0f",
   "metadata": {},
   "source": [
    "### preparing every single fucking prediction basically individually because i have no clue why the fuck they designed it this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59985b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>predicted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.309289</td>\n",
       "      <td>-7.987473</td>\n",
       "      <td>2.033544</td>\n",
       "      <td>-5.848030</td>\n",
       "      <td>4.629932</td>\n",
       "      <td>-0.159464</td>\n",
       "      <td>3.153248</td>\n",
       "      <td>-2.694118</td>\n",
       "      <td>1.627010</td>\n",
       "      <td>-1.486580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099627</td>\n",
       "      <td>0.207644</td>\n",
       "      <td>-0.267394</td>\n",
       "      <td>-0.244441</td>\n",
       "      <td>0.165865</td>\n",
       "      <td>0.035140</td>\n",
       "      <td>0.069252</td>\n",
       "      <td>-0.096012</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>5.648602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.051197</td>\n",
       "      <td>-14.817262</td>\n",
       "      <td>-3.191454</td>\n",
       "      <td>7.786214</td>\n",
       "      <td>3.490313</td>\n",
       "      <td>-2.639246</td>\n",
       "      <td>-11.014795</td>\n",
       "      <td>3.793033</td>\n",
       "      <td>-6.108306</td>\n",
       "      <td>8.710263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283728</td>\n",
       "      <td>-1.099406</td>\n",
       "      <td>-0.608685</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>0.478797</td>\n",
       "      <td>-0.294539</td>\n",
       "      <td>0.125870</td>\n",
       "      <td>0.364136</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>14.645488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.645348</td>\n",
       "      <td>15.046556</td>\n",
       "      <td>-2.854490</td>\n",
       "      <td>15.266036</td>\n",
       "      <td>5.571563</td>\n",
       "      <td>-6.217713</td>\n",
       "      <td>-4.483059</td>\n",
       "      <td>6.505590</td>\n",
       "      <td>7.553015</td>\n",
       "      <td>-2.707008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802120</td>\n",
       "      <td>-0.071728</td>\n",
       "      <td>-0.713378</td>\n",
       "      <td>0.418094</td>\n",
       "      <td>-0.213851</td>\n",
       "      <td>0.631917</td>\n",
       "      <td>-0.082412</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.198259</td>\n",
       "      <td>6.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.062933</td>\n",
       "      <td>24.521513</td>\n",
       "      <td>-0.551158</td>\n",
       "      <td>14.674147</td>\n",
       "      <td>4.318908</td>\n",
       "      <td>-1.790409</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>-0.631520</td>\n",
       "      <td>-4.318488</td>\n",
       "      <td>-3.672029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298908</td>\n",
       "      <td>0.712366</td>\n",
       "      <td>0.221489</td>\n",
       "      <td>-0.332866</td>\n",
       "      <td>-0.473422</td>\n",
       "      <td>-1.123427</td>\n",
       "      <td>-0.123125</td>\n",
       "      <td>-0.141773</td>\n",
       "      <td>-0.409851</td>\n",
       "      <td>11.433857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>-6.656838</td>\n",
       "      <td>-1.113078</td>\n",
       "      <td>-5.385633</td>\n",
       "      <td>8.819924</td>\n",
       "      <td>-1.193119</td>\n",
       "      <td>-0.659913</td>\n",
       "      <td>2.741127</td>\n",
       "      <td>-2.021801</td>\n",
       "      <td>0.928389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179057</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>-0.107786</td>\n",
       "      <td>0.107545</td>\n",
       "      <td>-0.057271</td>\n",
       "      <td>-0.489575</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.256880</td>\n",
       "      <td>8.733561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4         5          6  \\\n",
       "0   1.309289  -7.987473  2.033544  -5.848030  4.629932 -0.159464   3.153248   \n",
       "1   4.051197 -14.817262 -3.191454   7.786214  3.490313 -2.639246 -11.014795   \n",
       "2   3.645348  15.046556 -2.854490  15.266036  5.571563 -6.217713  -4.483059   \n",
       "3  40.062933  24.521513 -0.551158  14.674147  4.318908 -1.790409   0.391800   \n",
       "4   0.869189  -6.656838 -1.113078  -5.385633  8.819924 -1.193119  -0.659913   \n",
       "\n",
       "          7         8         9  ...       216       217       218       219  \\\n",
       "0 -2.694118  1.627010 -1.486580  ... -0.099627  0.207644 -0.267394 -0.244441   \n",
       "1  3.793033 -6.108306  8.710263  ...  0.283728 -1.099406 -0.608685  0.026220   \n",
       "2  6.505590  7.553015 -2.707008  ...  0.802120 -0.071728 -0.713378  0.418094   \n",
       "3 -0.631520 -4.318488 -3.672029  ... -0.298908  0.712366  0.221489 -0.332866   \n",
       "4  2.741127 -2.021801  0.928389  ... -0.179057  0.005642 -0.107786  0.107545   \n",
       "\n",
       "        220       221       222       223       224  predicted_y  \n",
       "0  0.165865  0.035140  0.069252 -0.096012 -0.092775     5.648602  \n",
       "1  0.478797 -0.294539  0.125870  0.364136  0.025421    14.645488  \n",
       "2 -0.213851  0.631917 -0.082412  0.018272  0.198259     6.038500  \n",
       "3 -0.473422 -1.123427 -0.123125 -0.141773 -0.409851    11.433857  \n",
       "4 -0.057271 -0.489575  0.577114  0.109490  0.256880     8.733561  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = pd.read_csv('0 out of 20.txt')\n",
    "p0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b686234",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('1 out of 20.txt')\n",
    "p2 = pd.read_csv('2 out of 20.txt')\n",
    "p3 = pd.read_csv('3 out of 20.txt')\n",
    "p4 = pd.read_csv('4 out of 20.txt')\n",
    "p5 = pd.read_csv('5 out of 20.txt')\n",
    "p6 = pd.read_csv('6 out of 20.txt')\n",
    "p7 = pd.read_csv('7 out of 20.txt')\n",
    "p8 = pd.read_csv('8 out of 20.txt')\n",
    "p9 = pd.read_csv('9 out of 20.txt')\n",
    "p10 = pd.read_csv('10 out of 20.txt')\n",
    "p11 = pd.read_csv('11 out of 20.txt')\n",
    "p12 = pd.read_csv('12 out of 20.txt')\n",
    "p13 = pd.read_csv('13 out of 20.txt')\n",
    "p14 = pd.read_csv('14 out of 20.txt')\n",
    "p15 = pd.read_csv('15 out of 20.txt')\n",
    "p16 = pd.read_csv('16 out of 20.txt')\n",
    "p17 = pd.read_csv('17 out of 20.txt')\n",
    "p18 = pd.read_csv('18 out of 20.txt')\n",
    "p19 = pd.read_csv('19 out of 20.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8ae9ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4403"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "821bf2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4403, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "232ebf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_pred['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdba8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "soon_pred.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c717624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.309289</td>\n",
       "      <td>-7.987473</td>\n",
       "      <td>2.033544</td>\n",
       "      <td>-5.848030</td>\n",
       "      <td>4.629932</td>\n",
       "      <td>-0.159464</td>\n",
       "      <td>3.153248</td>\n",
       "      <td>-2.694118</td>\n",
       "      <td>1.627010</td>\n",
       "      <td>-1.486580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267394</td>\n",
       "      <td>-0.244441</td>\n",
       "      <td>0.165865</td>\n",
       "      <td>0.035140</td>\n",
       "      <td>0.069252</td>\n",
       "      <td>-0.096012</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>5.648602</td>\n",
       "      <td>5380</td>\n",
       "      <td>5.648602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.051197</td>\n",
       "      <td>-14.817262</td>\n",
       "      <td>-3.191454</td>\n",
       "      <td>7.786214</td>\n",
       "      <td>3.490313</td>\n",
       "      <td>-2.639246</td>\n",
       "      <td>-11.014795</td>\n",
       "      <td>3.793033</td>\n",
       "      <td>-6.108306</td>\n",
       "      <td>8.710263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.608685</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>0.478797</td>\n",
       "      <td>-0.294539</td>\n",
       "      <td>0.125870</td>\n",
       "      <td>0.364136</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>14.645488</td>\n",
       "      <td>5381</td>\n",
       "      <td>14.645488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.645348</td>\n",
       "      <td>15.046556</td>\n",
       "      <td>-2.854490</td>\n",
       "      <td>15.266036</td>\n",
       "      <td>5.571563</td>\n",
       "      <td>-6.217713</td>\n",
       "      <td>-4.483059</td>\n",
       "      <td>6.505590</td>\n",
       "      <td>7.553015</td>\n",
       "      <td>-2.707008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.713378</td>\n",
       "      <td>0.418094</td>\n",
       "      <td>-0.213851</td>\n",
       "      <td>0.631917</td>\n",
       "      <td>-0.082412</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.198259</td>\n",
       "      <td>6.038500</td>\n",
       "      <td>5382</td>\n",
       "      <td>6.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.062933</td>\n",
       "      <td>24.521513</td>\n",
       "      <td>-0.551158</td>\n",
       "      <td>14.674147</td>\n",
       "      <td>4.318908</td>\n",
       "      <td>-1.790409</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>-0.631520</td>\n",
       "      <td>-4.318488</td>\n",
       "      <td>-3.672029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221489</td>\n",
       "      <td>-0.332866</td>\n",
       "      <td>-0.473422</td>\n",
       "      <td>-1.123427</td>\n",
       "      <td>-0.123125</td>\n",
       "      <td>-0.141773</td>\n",
       "      <td>-0.409851</td>\n",
       "      <td>11.433857</td>\n",
       "      <td>5383</td>\n",
       "      <td>11.433857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>-6.656838</td>\n",
       "      <td>-1.113078</td>\n",
       "      <td>-5.385633</td>\n",
       "      <td>8.819924</td>\n",
       "      <td>-1.193119</td>\n",
       "      <td>-0.659913</td>\n",
       "      <td>2.741127</td>\n",
       "      <td>-2.021801</td>\n",
       "      <td>0.928389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107786</td>\n",
       "      <td>0.107545</td>\n",
       "      <td>-0.057271</td>\n",
       "      <td>-0.489575</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.256880</td>\n",
       "      <td>8.733561</td>\n",
       "      <td>5384</td>\n",
       "      <td>8.733561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>-2.926289</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>-3.966814</td>\n",
       "      <td>-6.856167</td>\n",
       "      <td>5.294524</td>\n",
       "      <td>-2.137880</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>1.052964</td>\n",
       "      <td>-4.162008</td>\n",
       "      <td>0.794222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079663</td>\n",
       "      <td>0.259198</td>\n",
       "      <td>0.245877</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>0.471138</td>\n",
       "      <td>0.239067</td>\n",
       "      <td>-0.121709</td>\n",
       "      <td>0.355198</td>\n",
       "      <td>5620</td>\n",
       "      <td>0.355198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>-10.112903</td>\n",
       "      <td>-3.079507</td>\n",
       "      <td>-0.015125</td>\n",
       "      <td>-6.277171</td>\n",
       "      <td>-4.847001</td>\n",
       "      <td>-2.528476</td>\n",
       "      <td>1.795596</td>\n",
       "      <td>-2.581941</td>\n",
       "      <td>-0.334720</td>\n",
       "      <td>1.099594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769832</td>\n",
       "      <td>-0.281880</td>\n",
       "      <td>-0.439917</td>\n",
       "      <td>0.087468</td>\n",
       "      <td>0.312889</td>\n",
       "      <td>0.993270</td>\n",
       "      <td>0.838110</td>\n",
       "      <td>5.896849</td>\n",
       "      <td>5621</td>\n",
       "      <td>5.896849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>16.757335</td>\n",
       "      <td>17.107273</td>\n",
       "      <td>5.967247</td>\n",
       "      <td>-2.519582</td>\n",
       "      <td>-2.161496</td>\n",
       "      <td>-1.155645</td>\n",
       "      <td>2.888578</td>\n",
       "      <td>-3.226663</td>\n",
       "      <td>1.107484</td>\n",
       "      <td>-2.462463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336920</td>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.144106</td>\n",
       "      <td>-0.304598</td>\n",
       "      <td>0.511322</td>\n",
       "      <td>0.493485</td>\n",
       "      <td>0.176422</td>\n",
       "      <td>8.673186</td>\n",
       "      <td>5622</td>\n",
       "      <td>8.673186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>39.210624</td>\n",
       "      <td>37.300006</td>\n",
       "      <td>-7.530917</td>\n",
       "      <td>-5.087241</td>\n",
       "      <td>-3.273842</td>\n",
       "      <td>1.715115</td>\n",
       "      <td>4.613053</td>\n",
       "      <td>-2.297204</td>\n",
       "      <td>-0.365212</td>\n",
       "      <td>-5.914968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316450</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>0.357811</td>\n",
       "      <td>-0.231688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>0.366495</td>\n",
       "      <td>0.927809</td>\n",
       "      <td>8.933489</td>\n",
       "      <td>5623</td>\n",
       "      <td>8.933489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>2.080561</td>\n",
       "      <td>-6.937745</td>\n",
       "      <td>-1.195283</td>\n",
       "      <td>4.251943</td>\n",
       "      <td>7.542875</td>\n",
       "      <td>1.647720</td>\n",
       "      <td>-0.695412</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>5.663686</td>\n",
       "      <td>-4.625134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206026</td>\n",
       "      <td>-0.077552</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.034395</td>\n",
       "      <td>-0.039042</td>\n",
       "      <td>0.074333</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>8.237254</td>\n",
       "      <td>5624</td>\n",
       "      <td>8.237254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1         2          3         4         5  \\\n",
       "0      1.309289  -7.987473  2.033544  -5.848030  4.629932 -0.159464   \n",
       "1      4.051197 -14.817262 -3.191454   7.786214  3.490313 -2.639246   \n",
       "2      3.645348  15.046556 -2.854490  15.266036  5.571563 -6.217713   \n",
       "3     40.062933  24.521513 -0.551158  14.674147  4.318908 -1.790409   \n",
       "4      0.869189  -6.656838 -1.113078  -5.385633  8.819924 -1.193119   \n",
       "...         ...        ...       ...        ...       ...       ...   \n",
       "4398  -2.926289   0.064982 -3.966814  -6.856167  5.294524 -2.137880   \n",
       "4399 -10.112903  -3.079507 -0.015125  -6.277171 -4.847001 -2.528476   \n",
       "4400  16.757335  17.107273  5.967247  -2.519582 -2.161496 -1.155645   \n",
       "4401  39.210624  37.300006 -7.530917  -5.087241 -3.273842  1.715115   \n",
       "4402   2.080561  -6.937745 -1.195283   4.251943  7.542875  1.647720   \n",
       "\n",
       "              6         7         8         9  ...       218       219  \\\n",
       "0      3.153248 -2.694118  1.627010 -1.486580  ... -0.267394 -0.244441   \n",
       "1    -11.014795  3.793033 -6.108306  8.710263  ... -0.608685  0.026220   \n",
       "2     -4.483059  6.505590  7.553015 -2.707008  ... -0.713378  0.418094   \n",
       "3      0.391800 -0.631520 -4.318488 -3.672029  ...  0.221489 -0.332866   \n",
       "4     -0.659913  2.741127 -2.021801  0.928389  ... -0.107786  0.107545   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "4398   0.004979  1.052964 -4.162008  0.794222  ... -0.079663  0.259198   \n",
       "4399   1.795596 -2.581941 -0.334720  1.099594  ... -0.769832 -0.281880   \n",
       "4400   2.888578 -3.226663  1.107484 -2.462463  ... -0.336920  0.062235   \n",
       "4401   4.613053 -2.297204 -0.365212 -5.914968  ... -0.316450  0.014669   \n",
       "4402  -0.695412 -0.999936  5.663686 -4.625134  ... -0.206026 -0.077552   \n",
       "\n",
       "           220       221       222       223       224  predicted_y    id  \\\n",
       "0     0.165865  0.035140  0.069252 -0.096012 -0.092775     5.648602  5380   \n",
       "1     0.478797 -0.294539  0.125870  0.364136  0.025421    14.645488  5381   \n",
       "2    -0.213851  0.631917 -0.082412  0.018272  0.198259     6.038500  5382   \n",
       "3    -0.473422 -1.123427 -0.123125 -0.141773 -0.409851    11.433857  5383   \n",
       "4    -0.057271 -0.489575  0.577114  0.109490  0.256880     8.733561  5384   \n",
       "...        ...       ...       ...       ...       ...          ...   ...   \n",
       "4398  0.245877  0.029186  0.471138  0.239067 -0.121709     0.355198  5620   \n",
       "4399 -0.439917  0.087468  0.312889  0.993270  0.838110     5.896849  5621   \n",
       "4400  0.144106 -0.304598  0.511322  0.493485  0.176422     8.673186  5622   \n",
       "4401  0.357811 -0.231688  0.480586  0.366495  0.927809     8.933489  5623   \n",
       "4402  0.164698  0.034395 -0.039042  0.074333  0.082865     8.237254  5624   \n",
       "\n",
       "              y  \n",
       "0      5.648602  \n",
       "1     14.645488  \n",
       "2      6.038500  \n",
       "3     11.433857  \n",
       "4      8.733561  \n",
       "...         ...  \n",
       "4398   0.355198  \n",
       "4399   5.896849  \n",
       "4400   8.673186  \n",
       "4401   8.933489  \n",
       "4402   8.237254  \n",
       "\n",
       "[4403 rows x 228 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soon_pred.drop(columns = 'index', inplace = True)\n",
    "soon_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13cb8ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soon_pred['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "463c064f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>5.648602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>14.645488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>6.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>11.433857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>8.733561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          y\n",
       "0  5380   5.648602\n",
       "1  5381  14.645488\n",
       "2  5382   6.038500\n",
       "3  5383  11.433857\n",
       "4  5384   8.733561"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soon_pred = pd.concat([p0,p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18,p19])\n",
    "\n",
    "soon_pred.reset_index(inplace = True)\n",
    "soon_pred.drop(columns = 'index', inplace = True)\n",
    "\n",
    "soon_pred['id'] = test['id']\n",
    "soon_pred['y'] = soon_pred['predicted_y']\n",
    "\n",
    "fin_pred = soon_pred[['id','y']]\n",
    "fin_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f7ece35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4403"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_pred['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03048a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3819    3.711007e+06\n",
       "1309    3.607503e+06\n",
       "245     2.563847e+04\n",
       "3380    4.746643e+03\n",
       "1521    1.935133e+03\n",
       "406     1.414718e+03\n",
       "1618    4.029573e+02\n",
       "725     2.316629e+02\n",
       "3867    7.448112e+01\n",
       "987     7.060329e+01\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_pred['y'].sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce21a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_pred.to_csv('Submission 1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d5047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e768143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49b87466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4140"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "207*20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c601c",
   "metadata": {},
   "source": [
    "# Final Stacked Regressor\n",
    "\n",
    "Work such as cross validation and optimization shown down below this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc51aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arielle\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:813: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "C:\\Users\\Arielle\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:1066: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28064/2224317468.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                    \u001b[0mfinal_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                                    cv=KFold(n_splits=5,shuffle=True,random_state=1)).fit(reduced,y_train)\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "boostmodel = xgb.XGBRegressor(gamma = 10, learning_rate = 0.15, max_depth = 8, n_estimators = 100, reg_lambda = 1, scale_pos_weight = 1.5).fit(reduced,y_train)\n",
    "\n",
    "\n",
    "MARSmodel = Earth(max_degree=2,max_terms=400).fit(reduced,y_train)\n",
    "\n",
    "\n",
    "SVRmodel = SVR(C=45,epsilon=3).fit(reduced,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab00361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "ensemble_model = StackingRegressor(estimators=\n",
    "                                       [('boost',boostmodel),\n",
    "                                        ('mars', MARSmodel),\n",
    "                                        ('SVR', SVRmodel)],\n",
    "                                   final_estimator=RandomForestRegressor(max_depth = 20, n_estimators = 100),\n",
    "                                   n_jobs=-1,\n",
    "                                   cv=KFold(n_splits=5,shuffle=True,random_state=1)).fit(reduced,y_train)\n",
    "\n",
    "\n",
    "ensembleresults = ensemble_model.predict(pd.DataFrame(pca.transform(X_test_scaled)))\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(ensembleresults,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30c7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b76cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0fadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139288c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62d3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0904fc5",
   "metadata": {},
   "source": [
    "# Tuning submodels for stacked sequential model: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b4efe",
   "metadata": {},
   "source": [
    "##### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca493ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70d17029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2160 candidates, totalling 10800 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'gamma': [0, 10, 100.0],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'max_depth': [2, 3, 4, 5],\n",
       "                         'n_estimators': [6, 8, 10, 12, 14],\n",
       "                         'reg_lambda': [2, 10, 100, 200],\n",
       "                         'scale_pos_weight': [1.25, 1.5, 1.75]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning XGBoost\n",
    "\n",
    "param_grid = {'max_depth': [2,3,4,5],\n",
    "    'learning_rate': [0.01,0.05,0.1],\n",
    "    'reg_lambda':[2,10,100,200],\n",
    "    'n_estimators':[6,8,10,12,14],\n",
    "    'gamma':[0,10,1e2],\n",
    "    'scale_pos_weight':[1.25,1.5,1.75]}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state = 1),\n",
    "                              param_grid =param_grid,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 2,n_jobs=-1,cv = 5)\n",
    "\n",
    "optimal_params.fit(reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34cf4daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 14,\n",
       " 'reg_lambda': 2,\n",
       " 'scale_pos_weight': 1.5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d52f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.026756557150696"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgmodel = xgb.XGBRegressor(max_depth = \n",
    "                          \n",
    "                          \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d811de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=1, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'gamma': [10], 'learning_rate': [0.1, 0.5, 1],\n",
       "                         'max_depth': [10, 12, 15],\n",
       "                         'n_estimators': [15, 20, 25], 'reg_lambda': [1, 2],\n",
       "                         'scale_pos_weight': [1.5]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine search\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [10,12,15],\n",
    "    'learning_rate': [0.1,0.5,1],\n",
    "    'reg_lambda':[1,2],\n",
    "    'n_estimators':[15,20,25],\n",
    "    'gamma':[10],\n",
    "    'scale_pos_weight':[1.5]}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state = 1),\n",
    "                              param_grid =param_grid,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 2,n_jobs=-1,cv = 5)\n",
    "\n",
    "optimal_params.fit(reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d914fded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.959783293664952"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8a2c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 25,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1.5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed2eaa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=1, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'gamma': [10], 'learning_rate': [0.05, 0.1],\n",
       "                         'max_depth': [8, 10], 'n_estimators': [30, 40, 50],\n",
       "                         'reg_lambda': [1], 'scale_pos_weight': [1.5]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finer search\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [8,10],\n",
    "    'learning_rate': [0.05,0.1],\n",
    "    'reg_lambda':[1],\n",
    "    'n_estimators':[30,40,50],\n",
    "    'gamma':[10],\n",
    "    'scale_pos_weight':[1.5]}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state = 1),\n",
    "                              param_grid =param_grid,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 2,n_jobs=-1,cv = 5)\n",
    "\n",
    "optimal_params.fit(reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "540f88cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.626342443420496"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e5d7c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 50,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1.5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67eb7a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=1, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'gamma': [10], 'learning_rate': [0.1, 0.15],\n",
       "                         'max_depth': [8], 'n_estimators': [100, 150, 200],\n",
       "                         'reg_lambda': [1], 'scale_pos_weight': [1.5]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth': [8],\n",
    "    'learning_rate': [0.1,0.15],\n",
    "    'reg_lambda':[1],\n",
    "    'n_estimators':[100,150,200],\n",
    "    'gamma':[10],\n",
    "    'scale_pos_weight':[1.5]}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state = 1),\n",
    "                              param_grid =param_grid,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 2,n_jobs=-1,cv = 5)\n",
    "\n",
    "optimal_params.fit(reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42047a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.5538646556736"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "746fc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 10,\n",
       " 'learning_rate': 0.15,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 100,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1.5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edc0cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=10, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.15, max_delta_step=0,\n",
       "             max_depth=8, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1.5, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgmodel = xgb.XGBRegressor(gamma = 10, learning_rate = 0.15, max_depth = 8, n_estimators = 100, reg_lambda = 1, scale_pos_weight = 1.5)\n",
    "\n",
    "xgmodel.fit(reduced,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f0e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39627a70",
   "metadata": {},
   "source": [
    "##### Mars Model -- MARS IS USELESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8865ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "from pyearth import Earth\n",
    "\n",
    "#xgpreds = xgmodel.predict(reduced)\n",
    "\n",
    "\n",
    "param_grid1 = {'max_terms': [400,500,600,800],\n",
    "              'max_degree':[2,3,4,5,6]}\n",
    "\n",
    "\n",
    "#want to optimize on top of the xgboost model\n",
    "\n",
    "\n",
    "\n",
    "optimal_params1 = GridSearchCV(estimator=Earth(),\n",
    "                              param_grid =param_grid1,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 1,n_jobs=-1,cv = 5)\n",
    "\n",
    "optimal_params1.fit(reduced,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "582ed75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arielle\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:813: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "C:\\Users\\Arielle\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:1066: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    }
   ],
   "source": [
    "earthmodel = Earth(max_degree=2,max_terms=400).fit(xgpreds,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be2dd2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.885868279440967"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing on test set:\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "reduced_test = pd.DataFrame(pca.transform(X_test_scaled))\n",
    "\n",
    "preds = xgmodel.predict(reduced_test)\n",
    "\n",
    "preds1 = earthmodel.predict(preds)\n",
    "\n",
    "np.sqrt(mean_squared_error(preds1,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87d5258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.82839661561677"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65cc7178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3766,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgpreds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15ca12",
   "metadata": {},
   "source": [
    "SVR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "293bf74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(), n_jobs=-1,\n",
       "             param_grid={'C': [50, 40, 45], 'epsilon': [2, 3, 4, 5]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "\n",
    "#want to optimize on top of the xgboost model\n",
    "\n",
    "xgpreds = xgmodel.predict(reduced)\n",
    "\n",
    "param_grid2 = {'C': [50,40,45],\n",
    "              'epsilon':[2,3,4,5]}\n",
    "\n",
    "\n",
    "optimal_params2 = GridSearchCV(estimator=SVR(),\n",
    "                              param_grid =param_grid2,\n",
    "                              scoring = 'neg_root_mean_squared_error',\n",
    "                              verbose = 1,n_jobs=-1,cv = 5)\n",
    "\n",
    "optimal_params2.fit(reduced,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93aadf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 45, 'epsilon': 3}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bb572a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.331815991061774"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d413aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "svrmodel = SVR(C=45,epsilon=3).fit(reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea3b3b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.114262704817225"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take the average of the two because they both have different strengths\n",
    "\n",
    "earthmodel = Earth(max_degree=2,max_terms=400).fit(reduced,y_train)\n",
    "svrmodel = SVR(C=45,epsilon=3).fit(reduced,y_train)\n",
    "xgmodel = xgb.XGBRegressor(gamma = 10, learning_rate = 0.15, max_depth = 8, n_estimators = 100, reg_lambda = 1, scale_pos_weight = 1.5)\n",
    "xgmodel.fit(reduced,y_train)\n",
    "\n",
    "\n",
    "\n",
    "svrpreds = svrmodel.predict(reduced_test)\n",
    "\n",
    "xgpreds = xgmodel.predict(reduced_test)\n",
    "\n",
    "earthpreds = earthmodel.predict(reduced_test)\n",
    "\n",
    "\n",
    "\n",
    "fin_preds = (svrpreds+xgpreds+reduced_test)/3\n",
    "\n",
    "np.sqrt(mean_squared_error(fin_preds,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65191a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5815320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef63a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to test results, also use PCA to reduce test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10136885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a78f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7579f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1adf762b",
   "metadata": {},
   "source": [
    "# to predict on new data:\n",
    "\n",
    "- scale the data \n",
    "- run it through the same PCA transformation\n",
    "- run through XGBRegressor\n",
    "- take predictions and run them through MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39c0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34834b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab4773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2b8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddc465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9db00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4ce66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f54b133",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ca6db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': [20, 50, 60, 65, 70, 75, 80, 90, 100,\n",
       "                                         150, 200, 250, 300, 350, 400, 450, 500,\n",
       "                                         550, 600, 650],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "hyperparam_grid = {'weights':['uniform','distance'],'n_neighbors':[20, 50,60,65, 70, 75 ,80, 90,100, 150, 200, 250, 300, 350, 400, 450,500,550,600,650]}\n",
    "\n",
    "grid = GridSearchCV(knn, hyperparam_grid, verbose =1, scoring = 'neg_root_mean_squared_error',cv=5)\n",
    "\n",
    "grid.fit(X_train_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fdd2d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 65, 'weights': 'distance'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best hyperparameters:')\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dd957a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.841882719615871"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The RMSE is:')\n",
    "grid.best_score_*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584796b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "55c536f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.835351554708462"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##testing it again on PCA reduced data\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "hyperparam_grid = {'weights':['uniform','distance'],'n_neighbors':[20, 50,60,65, 70, 75 ,80, 90,100, 150, 200, 250, 300, 350, 400, 450,500,550,600,650]}\n",
    "\n",
    "grid = GridSearchCV(knn, hyperparam_grid, verbose =1, scoring = 'neg_root_mean_squared_error',cv=5)\n",
    "\n",
    "grid.fit(reduced,y_train)\n",
    "\n",
    "grid.best_score_*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "061338f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 50, 'weights': 'distance'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f62c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd497a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d33f215",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1be76987",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16240/1291870395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "\n",
    "#starting with adaboost\n",
    "model = AdaBoostRegressor(random_state=1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10,50,100]#,200,500]\n",
    "grid['learning_rate'] = [0.0001,0.001,0.01,0.1,1]\n",
    "grid['base_estimator'] = [DecisionTreeRegressor(max_depth=10),\n",
    "                         DecisionTreeRegressor(max_depth=20),\n",
    "                         DecisionTreeRegressor(max_depth=50)]#,\n",
    "                         #DecisionTreeRegressor(max_depth=70),\n",
    "                         #DecisionTreeRegressor(max_depth=100)]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,scoring='neg_mean_squared_error')\n",
    "\n",
    "\n",
    "grid_result = grid_search.fit(X_train_scaled,y_train)\n",
    "\n",
    "grid_result.best_score_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#WE CAN USE GOOGLE COLLAB TO PROCESS THINGS FASTER!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4c631f00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16240/1436759005.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_result' is not defined"
     ]
    }
   ],
   "source": [
    "grid_result.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b217095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c5400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0650db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e0b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aea749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c1e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46750c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea685526",
   "metadata": {},
   "source": [
    "#### Neural Net Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae7a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba07c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis = -1)\n",
    "\n",
    "\n",
    "normalizer.adapt(np.array(X_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27d334c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(normalizer.mean.numpy())\n",
    "#first = np.array(X_train[:1])\n",
    "\n",
    "#with np.printoptions(precision=2, suppress=True):\n",
    " #   print('First example:', first)\n",
    " #   print()\n",
    " #   print('Normalized:', normalizer(first).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8250839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 163ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.2198023 ],\n",
       "       [-1.5010332 ],\n",
       "       [ 0.45019075],\n",
       "       [-3.727004  ],\n",
       "       [-0.42273405],\n",
       "       [ 1.0823498 ],\n",
       "       [-0.4042282 ],\n",
       "       [ 1.094361  ],\n",
       "       [-0.3669465 ],\n",
       "       [-1.903799  ]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = tf.keras.Sequential([\n",
    "    #normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "linear_model.predict(X_train_scaled[:10])\n",
    "\n",
    "#IT WAS A PROBLEM WITH THE NORMALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0cf9cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = tf.keras.Sequential(layers=[\n",
    "      #norm,\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 600, activation='relu'),\n",
    "        layers.Dense(units = 400, activation='relu'),\n",
    "        layers.Dense(units = 400, activation='relu'),\n",
    "        layers.Dense(units = 400, activation='relu'),\n",
    "        layers.Dense(units = 400, activation='relu'),\n",
    "        layers.Dense(units = 300, activation='relu'),\n",
    "        layers.Dense(units = 300, activation='relu'),\n",
    "        layers.Dense(units = 200, activation='relu'),\n",
    "        layers.Dense(units = 200, activation='relu'),        \n",
    "        layers.Dense(units = 200, activation='relu'),\n",
    "        layers.Dense(units = 200, activation='relu'),\n",
    "        layers.Dense(units = 200, activation='relu'),\n",
    "        layers.Dense(units = 200, activation='relu'),\n",
    "        layers.Dense(units = 100, activation='relu'),\n",
    "        layers.Dense(units = 100, activation='relu'),\n",
    "        layers.Dense(units = 100, activation='relu'),\n",
    "        layers.Dense(units = 100, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(units = 64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    #model.add(\n",
    "    #    keras.layers.Dense(\n",
    "    #        units=1,\n",
    "    #        input_shape = (1, ),\n",
    "    #        kernel_initializer='glorot_uniform',\n",
    "    #        bias_initializer='zeros',\n",
    "    #        activation='sigmoid')\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(0.0001,clipnorm=1,clipvalue=1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8e79951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "#dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6d908010",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dnn_model.fit(\n",
    "    np.array(X_train_scaled),\n",
    "    np.array(y_train),\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "11bf2b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "plot_loss(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "eacc142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 2s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = dnn_model.predict(np.array(X_test)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "99e5a8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.653239729496534, nan, nan, ..., nan, nan, 2.9779298028995904],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds/10**37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d337d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1890d81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb717c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f3ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ece7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fac04e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02052de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fba6dd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16240/2386629555.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(X_train_scaled, y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           validation_data=(X_test_scaled, y_test))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=100,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f9deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
